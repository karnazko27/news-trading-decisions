{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fxvqaifJPw4J",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fxvqaifJPw4J",
    "outputId": "ab0852d7-3e22-453d-8d29-d26ba3e05ce0"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "UHhw-xKWP5au",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UHhw-xKWP5au",
    "outputId": "1b54d071-5fd7-42ff-bd2b-ffcf9c0bc9e3"
   },
   "outputs": [],
   "source": [
    "# cd drive/MyDrive/IE7500_GroupB/Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87f87f3e-f78a-4f25-9c1e-e81cae8ff0d4",
   "metadata": {
    "id": "87f87f3e-f78a-4f25-9c1e-e81cae8ff0d4"
   },
   "outputs": [],
   "source": [
    "# load necesary libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45c114d1-2f7d-44f0-a037-fd53cd17e1f8",
   "metadata": {
    "id": "45c114d1-2f7d-44f0-a037-fd53cd17e1f8"
   },
   "outputs": [],
   "source": [
    "dtypes_dict = {'headline': 'object',\n",
    "               'url': 'object',\n",
    "               'publisher': 'object',\n",
    "               'stock': 'object',\n",
    "               'tokens': 'object',\n",
    "               'normalized_tokens': 'object',\n",
    "               'filtered_tokens': 'object',\n",
    "               'lemmas': 'object',\n",
    "               'sentiment_score': 'float64',\n",
    "               'Name': 'object',\n",
    "               'Market Cap': 'float64',\n",
    "               'Country': 'object',\n",
    "               'IPO Year': 'float64',\n",
    "               'Sector': 'object',\n",
    "               'Industry': 'object',\n",
    "               'year': 'int32',\n",
    "               'month': 'int32',\n",
    "               'day_of_week': 'int32',\n",
    "               'sentiment_label': 'int64',\n",
    "               'headline_length': 'int64',\n",
    "               'word_count': 'int64',\n",
    "               'Market_Cap_Category': 'object',\n",
    "               'recommendation': 'object',\n",
    "               'cap_Large': 'bool',\n",
    "               'cap_Medium': 'bool',\n",
    "               'cap_Mega': 'bool',\n",
    "               'cap_Micro': 'bool',\n",
    "               'cap_Nano': 'bool',\n",
    "               'cap_Small': 'bool',\n",
    "               'sector_Basic Materials': 'bool',\n",
    "               'sector_Consumer Discretionary': 'bool',\n",
    "               'sector_Consumer Staples': 'bool',\n",
    "               'sector_Energy': 'bool',\n",
    "               'sector_Finance': 'bool',\n",
    "               'sector_Health Care': 'bool',\n",
    "               'sector_Industrials': 'bool',\n",
    "               'sector_Miscellaneous': 'bool',\n",
    "               'sector_Real Estate': 'bool',\n",
    "               'sector_Technology': 'bool',\n",
    "               'sector_Telecommunications': 'bool',\n",
    "               'sector_Utilities': 'bool', 'recommendation_label': 'int64',\n",
    "               'publisher_label': 'int64', 'country_label': 'int64',\n",
    "               'industry_label': 'int64'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff4fb8d8-cb25-47c5-b2b4-4f1d5b0f7e0a",
   "metadata": {
    "id": "ff4fb8d8-cb25-47c5-b2b4-4f1d5b0f7e0a"
   },
   "outputs": [],
   "source": [
    "# load dataframes to use\n",
    "df_main = pd.read_csv(\"saved_dfs/df_for_models.csv\", dtype=dtypes_dict,\n",
    "                      parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe2c9cd5-42e4-406c-a58e-5b1931384587",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 602
    },
    "id": "fe2c9cd5-42e4-406c-a58e-5b1931384587",
    "outputId": "5e8877ba-0b01-4e39-9ca8-dbe5df0d440a",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>url</th>\n",
       "      <th>publisher</th>\n",
       "      <th>date</th>\n",
       "      <th>stock</th>\n",
       "      <th>tokens</th>\n",
       "      <th>normalized_tokens</th>\n",
       "      <th>filtered_tokens</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>...</th>\n",
       "      <th>sector_Industrials</th>\n",
       "      <th>sector_Miscellaneous</th>\n",
       "      <th>sector_Real Estate</th>\n",
       "      <th>sector_Technology</th>\n",
       "      <th>sector_Telecommunications</th>\n",
       "      <th>sector_Utilities</th>\n",
       "      <th>recommendation_label</th>\n",
       "      <th>publisher_label</th>\n",
       "      <th>country_label</th>\n",
       "      <th>industry_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agilent Technologies Announces Pricing of $5……...</td>\n",
       "      <td>http://www.gurufocus.com/news/1153187/agilent-...</td>\n",
       "      <td>GuruFocus</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>A</td>\n",
       "      <td>['Agilent', 'Technologies', 'Announces', 'Pric...</td>\n",
       "      <td>['agilent', 'technologies', 'announces', 'pric...</td>\n",
       "      <td>['agilent', 'technologies', 'announces', 'pric...</td>\n",
       "      <td>['agilent', 'technology', 'announces', 'pricin...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Agilent (A) Gears Up for Q2 Earnings: What's i...</td>\n",
       "      <td>http://www.zacks.com/stock/news/931205/agilent...</td>\n",
       "      <td>Zacks</td>\n",
       "      <td>2020-05-18</td>\n",
       "      <td>A</td>\n",
       "      <td>['Agilent', '(', 'A', ')', 'Gears', 'Up', 'for...</td>\n",
       "      <td>['agilent', 'a', 'gears', 'up', 'for', 'q2', '...</td>\n",
       "      <td>['agilent', 'gears', 'q2', 'earnings', 'cards']</td>\n",
       "      <td>['agilent', 'gear', 'q2', 'earnings', 'card']</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>45</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>J.P. Morgan Asset Management Announces Liquida...</td>\n",
       "      <td>http://www.gurufocus.com/news/1138923/jp-morga...</td>\n",
       "      <td>GuruFocus</td>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>A</td>\n",
       "      <td>['J.P.', 'Morgan', 'Asset', 'Management', 'Ann...</td>\n",
       "      <td>['morgan', 'asset', 'management', 'announces',...</td>\n",
       "      <td>['morgan', 'asset', 'management', 'announces',...</td>\n",
       "      <td>['morgan', 'asset', 'management', 'announces',...</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pershing Square Capital Management, L.P. Buys ...</td>\n",
       "      <td>http://www.gurufocus.com/news/1138704/pershing...</td>\n",
       "      <td>GuruFocus</td>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>A</td>\n",
       "      <td>['Pershing', 'Square', 'Capital', 'Management'...</td>\n",
       "      <td>['pershing', 'square', 'capital', 'management'...</td>\n",
       "      <td>['pershing', 'square', 'capital', 'management'...</td>\n",
       "      <td>['pershing', 'square', 'capital', 'management'...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Agilent Awards Trilogy Sciences with a Golden ...</td>\n",
       "      <td>http://www.gurufocus.com/news/1134012/agilent-...</td>\n",
       "      <td>GuruFocus</td>\n",
       "      <td>2020-05-12</td>\n",
       "      <td>A</td>\n",
       "      <td>['Agilent', 'Awards', 'Trilogy', 'Sciences', '...</td>\n",
       "      <td>['agilent', 'awards', 'trilogy', 'sciences', '...</td>\n",
       "      <td>['agilent', 'awards', 'trilogy', 'sciences', '...</td>\n",
       "      <td>['agilent', 'award', 'trilogy', 'science', 'go...</td>\n",
       "      <td>0.4588</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  \\\n",
       "0  Agilent Technologies Announces Pricing of $5……...   \n",
       "1  Agilent (A) Gears Up for Q2 Earnings: What's i...   \n",
       "2  J.P. Morgan Asset Management Announces Liquida...   \n",
       "3  Pershing Square Capital Management, L.P. Buys ...   \n",
       "4  Agilent Awards Trilogy Sciences with a Golden ...   \n",
       "\n",
       "                                                 url  publisher       date  \\\n",
       "0  http://www.gurufocus.com/news/1153187/agilent-...  GuruFocus 2020-06-01   \n",
       "1  http://www.zacks.com/stock/news/931205/agilent...      Zacks 2020-05-18   \n",
       "2  http://www.gurufocus.com/news/1138923/jp-morga...  GuruFocus 2020-05-15   \n",
       "3  http://www.gurufocus.com/news/1138704/pershing...  GuruFocus 2020-05-15   \n",
       "4  http://www.gurufocus.com/news/1134012/agilent-...  GuruFocus 2020-05-12   \n",
       "\n",
       "  stock                                             tokens  \\\n",
       "0     A  ['Agilent', 'Technologies', 'Announces', 'Pric...   \n",
       "1     A  ['Agilent', '(', 'A', ')', 'Gears', 'Up', 'for...   \n",
       "2     A  ['J.P.', 'Morgan', 'Asset', 'Management', 'Ann...   \n",
       "3     A  ['Pershing', 'Square', 'Capital', 'Management'...   \n",
       "4     A  ['Agilent', 'Awards', 'Trilogy', 'Sciences', '...   \n",
       "\n",
       "                                   normalized_tokens  \\\n",
       "0  ['agilent', 'technologies', 'announces', 'pric...   \n",
       "1  ['agilent', 'a', 'gears', 'up', 'for', 'q2', '...   \n",
       "2  ['morgan', 'asset', 'management', 'announces',...   \n",
       "3  ['pershing', 'square', 'capital', 'management'...   \n",
       "4  ['agilent', 'awards', 'trilogy', 'sciences', '...   \n",
       "\n",
       "                                     filtered_tokens  \\\n",
       "0  ['agilent', 'technologies', 'announces', 'pric...   \n",
       "1    ['agilent', 'gears', 'q2', 'earnings', 'cards']   \n",
       "2  ['morgan', 'asset', 'management', 'announces',...   \n",
       "3  ['pershing', 'square', 'capital', 'management'...   \n",
       "4  ['agilent', 'awards', 'trilogy', 'sciences', '...   \n",
       "\n",
       "                                              lemmas  sentiment_score  ...  \\\n",
       "0  ['agilent', 'technology', 'announces', 'pricin...           0.0000  ...   \n",
       "1      ['agilent', 'gear', 'q2', 'earnings', 'card']           0.0000  ...   \n",
       "2  ['morgan', 'asset', 'management', 'announces',...           0.3612  ...   \n",
       "3  ['pershing', 'square', 'capital', 'management'...           0.0000  ...   \n",
       "4  ['agilent', 'award', 'trilogy', 'science', 'go...           0.4588  ...   \n",
       "\n",
       "  sector_Industrials  sector_Miscellaneous sector_Real Estate  \\\n",
       "0               True                 False              False   \n",
       "1               True                 False              False   \n",
       "2               True                 False              False   \n",
       "3               True                 False              False   \n",
       "4               True                 False              False   \n",
       "\n",
       "   sector_Technology sector_Telecommunications sector_Utilities  \\\n",
       "0              False                     False            False   \n",
       "1              False                     False            False   \n",
       "2              False                     False            False   \n",
       "3              False                     False            False   \n",
       "4              False                     False            False   \n",
       "\n",
       "   recommendation_label  publisher_label  country_label  industry_label  \n",
       "0                     1                4             45              18  \n",
       "1                     1               16             45              18  \n",
       "2                     1                4             45              18  \n",
       "3                     1                4             45              18  \n",
       "4                     1                4             45              18  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_main.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e917439f-655f-4d23-9a7b-7690f82b1bb4",
   "metadata": {
    "id": "e917439f-655f-4d23-9a7b-7690f82b1bb4"
   },
   "source": [
    "Create Vectors from Headlines (Vectorization Models)\n",
    "\n",
    "To generate vectors for the headline column, you can use different NLP vectorization techniques, including:\n",
    "\n",
    "TF-IDF (Term Frequency - Inverse Document Frequency)\n",
    "\n",
    "Count Vectorizer (Bag of Words)\n",
    "\n",
    "Word2Vec (Pre-trained Word Embeddings)\n",
    "\n",
    "Doc2Vec (Sentence-Level Embeddings)\n",
    "\n",
    "BERT Embeddings (Transformer-based Representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dae2724-2e73-493a-9383-035e6d71d26e",
   "metadata": {
    "id": "5dae2724-2e73-493a-9383-035e6d71d26e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccafb75-5281-4d0a-baa3-8e4cd1d91289",
   "metadata": {
    "id": "5ccafb75-5281-4d0a-baa3-8e4cd1d91289"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "372c86ce-0360-48b7-b664-391e6d4697e7",
   "metadata": {
    "id": "372c86ce-0360-48b7-b664-391e6d4697e7"
   },
   "source": [
    "# Goal 1: Predict Buy / Hold / Sell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb53203-830b-4639-b55a-eb7c06a8cb9d",
   "metadata": {
    "id": "4eb53203-830b-4639-b55a-eb7c06a8cb9d"
   },
   "source": [
    "## Method 4: MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2b04009-e12f-4324-800f-a1f9a16fab7c",
   "metadata": {
    "id": "b2b04009-e12f-4324-800f-a1f9a16fab7c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-06 14:45:01.940840: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743965101.962533  930462 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743965101.969584  930462 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743965101.987611  930462 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743965101.987621  930462 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743965101.987624  930462 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743965101.987626  930462 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-06 14:45:01.993641: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b56027a2-e00c-4f03-b8f4-59b46e403e66",
   "metadata": {
    "id": "b56027a2-e00c-4f03-b8f4-59b46e403e66"
   },
   "outputs": [],
   "source": [
    "# Features and target\n",
    "features = [\"sentiment_score\", \"publisher_label\", \"country_label\", \"industry_label\",\n",
    "            \"sector_Industrials\", \"sector_Miscellaneous\", \"sector_Real Estate\",\n",
    "            \"sector_Technology\", \"sector_Telecommunications\", \"sector_Utilities\"]\n",
    "target = \"recommendation_label\"\n",
    "\n",
    "# Split\n",
    "X = df_main[features].fillna(0)\n",
    "y = df_main[target]\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train_raw, y_test_raw = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert labels to one-hot for softmax classification\n",
    "y_train = to_categorical(y_train_raw)\n",
    "y_test = to_categorical(y_test_raw)\n",
    "num_classes = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19ba8183-e296-4805-86db-b5c771b00556",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 344
    },
    "id": "19ba8183-e296-4805-86db-b5c771b00556",
    "outputId": "942f7f8d-3160-472e-a88a-09d69a768dea"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/courses/IE7500.202530/shared/conda_env_1/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "I0000 00:00:1743965110.443077  930462 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11437 MB memory:  -> device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:03:00.0, compute capability: 6.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m1,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,859</span> (38.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,859\u001b[0m (38.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,859</span> (38.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,859\u001b[0m (38.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(128, activation=\"relu\", input_shape=(X_train_scaled.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    Dropout(0.3),\n",
    "    Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b653f9ca-2253-42df-9df6-1e89df827cd1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b653f9ca-2253-42df-9df6-1e89df827cd1",
    "outputId": "e9c81885-bbc8-4e78-8e6a-4501987568b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1743965113.557545  930593 service.cc:152] XLA service 0x14dcdc004d30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1743965113.557598  930593 service.cc:160]   StreamExecutor device (0): Tesla P100-PCIE-12GB, Compute Capability 6.0\n",
      "2025-04-06 14:45:13.626447: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1743965113.970075  930593 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  41/5768\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.6311 - loss: 0.8982   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1743965116.780918  930593 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5768/5768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - accuracy: 0.9594 - loss: 0.1062 - val_accuracy: 0.9982 - val_loss: 0.0063\n",
      "Epoch 2/3\n",
      "\u001b[1m5768/5768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9960 - loss: 0.0105 - val_accuracy: 0.9989 - val_loss: 0.0030\n",
      "Epoch 3/3\n",
      "\u001b[1m5768/5768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9972 - loss: 0.0072 - val_accuracy: 0.9986 - val_loss: 0.0036\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_data=(X_test_scaled, y_test),\n",
    "    epochs=3,\n",
    "    batch_size=256,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b054f8a-9070-4533-97d4-e0d0f069317b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2b054f8a-9070-4533-97d4-e0d0f069317b",
    "outputId": "8eaf27a8-e075-4993-8af7-b8bbfb2c5227"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11535/11535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step\n",
      "MLP Keras Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     37064\n",
      "           1       1.00      1.00      1.00    317370\n",
      "           2       0.99      0.99      0.99     14678\n",
      "\n",
      "    accuracy                           1.00    369112\n",
      "   macro avg       1.00      1.00      1.00    369112\n",
      "weighted avg       1.00      1.00      1.00    369112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict classes\n",
    "y_pred_probs = model.predict(X_test_scaled)\n",
    "y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Classification report\n",
    "print(\"MLP Keras Model Performance:\")\n",
    "print(classification_report(y_true_classes, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b221b1f-278d-4129-a5b9-04ced495dde4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5b221b1f-278d-4129-a5b9-04ced495dde4",
    "outputId": "906d736f-f180-4fa8-d246-1724e70c5b51"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as keras_mlp_recommendation_model.h5\n"
     ]
    }
   ],
   "source": [
    "model.save(\"keras_mlp_recommendation_model.h5\")\n",
    "print(\"Model saved as keras_mlp_recommendation_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d6a5c0-a32f-4aec-8278-542ae2840539",
   "metadata": {
    "id": "c4d6a5c0-a32f-4aec-8278-542ae2840539"
   },
   "source": [
    "## Method 5: LSTM for Text-Based Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c42dcd7-74e8-4447-aa11-df1e59a2033b",
   "metadata": {
    "id": "0c42dcd7-74e8-4447-aa11-df1e59a2033b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bfc74156-f546-41b9-8bf8-10621923d0ca",
   "metadata": {
    "id": "bfc74156-f546-41b9-8bf8-10621923d0ca"
   },
   "outputs": [],
   "source": [
    "# Convert lemmas list to space-separated strings\n",
    "df_main[\"lemmas_str\"] = df_main[\"lemmas\"].apply(lambda x: \" \".join(x) if isinstance(x, list) else \"\")\n",
    "\n",
    "# Define text and target\n",
    "texts = df_main[\"lemmas_str\"].fillna(\"\")\n",
    "labels = df_main[\"recommendation_label\"]\n",
    "\n",
    "# Train/test split\n",
    "X_train_text, X_test_text, y_train_raw, y_test_raw = train_test_split(\n",
    "    texts, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# One-hot encode target\n",
    "y_train = to_categorical(y_train_raw)\n",
    "y_test = to_categorical(y_test_raw)\n",
    "num_classes = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b3e9ecd-62f8-4797-bb3d-6beacc619afe",
   "metadata": {
    "id": "4b3e9ecd-62f8-4797-bb3d-6beacc619afe"
   },
   "outputs": [],
   "source": [
    "# Tokenize text\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train_text)\n",
    "\n",
    "# Convert to sequences\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train_text)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test_text)\n",
    "\n",
    "# Pad sequences to the same length\n",
    "max_len = 30\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len, padding=\"post\", truncating=\"post\")\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len, padding=\"post\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3a8c1f6-fac2-4cd6-8dc5-8d01bc529e8c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "id": "d3a8c1f6-fac2-4cd6-8dc5-8d01bc529e8c",
    "outputId": "d5df19db-e6ff-48fa-e53b-aa91c0434561"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/courses/IE7500.202530/shared/conda_env_1/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedding_dim = 100\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=10000, output_dim=embedding_dim, input_length=max_len),\n",
    "    LSTM(64, return_sequences=False),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation=\"relu\"),\n",
    "    Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JbXNETkPz5lK",
   "metadata": {
    "id": "JbXNETkPz5lK"
   },
   "source": [
    "Running 3 epochs to save time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5aac3435-43c6-45e8-bfd3-4b04694e4b75",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5aac3435-43c6-45e8-bfd3-4b04694e4b75",
    "outputId": "c68b4d3c-947a-4b7e-da95-4d4423bdcca8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m2884/2884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 14ms/step - accuracy: 0.8580 - loss: 0.4987 - val_accuracy: 0.8598 - val_loss: 0.4906\n",
      "Epoch 2/3\n",
      "\u001b[1m2884/2884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 14ms/step - accuracy: 0.8609 - loss: 0.4871 - val_accuracy: 0.8598 - val_loss: 0.4905\n",
      "Epoch 3/3\n",
      "\u001b[1m2884/2884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 14ms/step - accuracy: 0.8611 - loss: 0.4858 - val_accuracy: 0.8598 - val_loss: 0.4927\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train_pad, y_train,\n",
    "    validation_data=(X_test_pad, y_test),\n",
    "    epochs=3,\n",
    "    batch_size=512\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8cfa4833-504f-4ad7-b2ae-4b1ac6547904",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8cfa4833-504f-4ad7-b2ae-4b1ac6547904",
    "outputId": "7bd255c2-cf63-4c05-dd20-751dec44ace1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11535/11535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 3ms/step\n",
      "LSTM Model Performance on Lemmas:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00     37064\n",
      "           1       0.86      1.00      0.92    317370\n",
      "           2       0.00      0.00      0.00     14678\n",
      "\n",
      "    accuracy                           0.86    369112\n",
      "   macro avg       0.29      0.33      0.31    369112\n",
      "weighted avg       0.74      0.86      0.80    369112\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/courses/IE7500.202530/shared/conda_env_1/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/courses/IE7500.202530/shared/conda_env_1/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/courses/IE7500.202530/shared/conda_env_1/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Predict classes\n",
    "y_pred_probs = model.predict(X_test_pad)\n",
    "y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Classification report\n",
    "print(\"LSTM Model Performance on Lemmas:\")\n",
    "print(classification_report(y_true_classes, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fbc0181f-faf1-48a1-988d-ef0eb7d3188e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fbc0181f-faf1-48a1-988d-ef0eb7d3188e",
    "outputId": "7439b7b9-a686-4eb7-b34d-e8ac4ea02b64"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as lstm_text_recommendation_model.h5\n"
     ]
    }
   ],
   "source": [
    "model.save(\"lstm_text_recommendation_model.h5\")\n",
    "print(\"Model saved as lstm_text_recommendation_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a68d4b5-6f67-494a-b30a-79e5b2451e03",
   "metadata": {
    "id": "9a68d4b5-6f67-494a-b30a-79e5b2451e03"
   },
   "source": [
    "## Method 6: BERT + MLP (Transformer-Based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "099321db-5cfa-4a71-916d-fdf884735d53",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "099321db-5cfa-4a71-916d-fdf884735d53",
    "outputId": "e8c0fc24-3711-4069-8272-d494f8d168ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ensorflow (/courses/IE7500.202530/shared/conda_env_1/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "Requirement already satisfied: transformers in /courses/IE7500.202530/shared/conda_env_1/lib/python3.12/site-packages (4.47.1)\n",
      "Requirement already satisfied: datasets in /courses/IE7500.202530/shared/conda_env_1/lib/python3.12/site-packages (3.2.0)\n",
      "Requirement already satisfied: filelock in /courses/IE7500.202530/shared/conda_env_1/lib/python3.12/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /courses/IE7500.202530/shared/conda_env_1/lib/python3.12/site-packages (from transformers) (0.27.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /courses/IE7500.202530/shared/conda_env_1/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /courses/IE7500.202530/shared/conda_env_1/lib/python3.12/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /courses/IE7500.202530/shared/conda_env_1/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /courses/IE7500.202530/shared/conda_env_1/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /courses/IE7500.202530/shared/conda_env_1/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /courses/IE7500.202530/shared/conda_env_1/lib/python3.12/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /courses/IE7500.202530/shared/conda_env_1/lib/python3.12/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /courses/IE7500.202530/shared/conda_env_1/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /courses/IE7500.202530/shared/conda_env_1/lib/python3.12/site-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /courses/IE7500.202530/shared/conda_env_1/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /courses/IE7500.202530/shared/conda_env_1/lib/python3.12/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /courses/IE7500.202530/shared/conda_env_1/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /courses/IE7500.202530/shared/conda_env_1/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /courses/IE7500.202530/shared/conda_env_1/lib/python3.12/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /courses/IE7500.202530/shared/conda_env_1/lib/python3.12/site-packages (from datasets) (3.11.11)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /courses/IE7500.202530/shared/conda_env_1/lib/python3.12/site-packages (from aiohttp->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /courses/IE7500.202530/shared/conda_env_1/lib/python3.12/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /courses/IE7500.202530/shared/conda_env_1/lib/python3.12/site-packages (from aiohttp->datasets) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /courses/IE7500.202530/shared/conda_env_1/lib/python3.12/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /courses/IE7500.202530/shared/conda_env_1/lib/python3.12/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /courses/IE7500.202530/shared/conda_env_1/lib/python3.12/site-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /courses/IE7500.202530/shared/conda_env_1/lib/python3.12/site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /courses/IE7500.202530/shared/conda_env_1/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /courses/IE7500.202530/shared/conda_env_1/lib/python3.12/site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /courses/IE7500.202530/shared/conda_env_1/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /courses/IE7500.202530/shared/conda_env_1/lib/python3.12/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /courses/IE7500.202530/shared/conda_env_1/lib/python3.12/site-packages (from requests->transformers) (2024.12.14)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /courses/IE7500.202530/shared/conda_env_1/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /courses/IE7500.202530/shared/conda_env_1/lib/python3.12/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /courses/IE7500.202530/shared/conda_env_1/lib/python3.12/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /courses/IE7500.202530/shared/conda_env_1/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ensorflow (/courses/IE7500.202530/shared/conda_env_1/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "vGINBxfoHnCT",
   "metadata": {
    "id": "vGINBxfoHnCT"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/courses/IE7500.202530/shared/conda_env_1/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0v-kwgY1HyTJ",
   "metadata": {
    "id": "0v-kwgY1HyTJ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Convert lemmas to joined string\n",
    "df_main[\"lemmas_str\"] = df_main[\"lemmas\"].apply(lambda x: \" \".join(x) if isinstance(x, list) else \"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "02d33c11-66d6-4da9-a6d9-176674947523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lemmas to joined string\n",
    "def get_bert_embedding(texts, batch_size=32):\n",
    "    embeddings = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i + batch_size]\n",
    "        inputs = tokenizer(batch_texts, return_tensors='pt', truncation=True, padding=True, max_length=64)\n",
    "        with torch.no_grad():\n",
    "            outputs = bert_model(**inputs)\n",
    "        batch_embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "        embeddings.append(batch_embeddings)\n",
    "    return np.vstack(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "76e2f293-1596-46ed-9691-ae3254e14c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "bert_model.to(device)\n",
    "\n",
    "def get_bert_embedding(texts, batch_size=64):\n",
    "    embeddings = []\n",
    "\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Encoding BERT\"):\n",
    "        batch_texts = texts[i:i + batch_size]\n",
    "\n",
    "        # Tokenize batch\n",
    "        inputs = tokenizer(batch_texts, return_tensors='pt', truncation=True,\n",
    "                           padding=True, max_length=64).to(device)\n",
    "\n",
    "        # Disable gradient tracking and use inference mode for speed\n",
    "        with torch.inference_mode():\n",
    "            outputs = bert_model(**inputs)\n",
    "            # Mean pooling over token dimension\n",
    "            batch_embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "\n",
    "        embeddings.append(batch_embeddings)\n",
    "\n",
    "    return np.vstack(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1be6dc3b-46d8-489a-8bc3-4c0edc827e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "169685db-65b9-47a8-91b0-4415a2a0c929",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding BERT: 100%|██████████| 28837/28837 [19:23<00:00, 24.78it/s]  \n"
     ]
    }
   ],
   "source": [
    "bert_vectors = get_bert_embedding(df_main[\"lemmas_str\"].tolist())\n",
    "np.save(\"bert_vectors.npy\", bert_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "Z9leCKoWH_Tm",
   "metadata": {
    "id": "Z9leCKoWH_Tm"
   },
   "outputs": [],
   "source": [
    "# Convert BERT vectors to a feature matrix\n",
    "X = np.load(\"bert_vectors.npy\", allow_pickle=True)\n",
    "y = df_main[\"recommendation_label\"]\n",
    "svd = TruncatedSVD(n_components=50, random_state=42)\n",
    "X_reduced = svd.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ATPoFrQvH_RA",
   "metadata": {
    "id": "ATPoFrQvH_RA"
   },
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ePSewyZdH_OY",
   "metadata": {
    "id": "ePSewyZdH_OY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT Embeddings + MLP Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00     37064\n",
      "           1       0.86      1.00      0.92    317370\n",
      "           2       0.00      0.00      0.00     14678\n",
      "\n",
      "    accuracy                           0.86    369112\n",
      "   macro avg       0.29      0.33      0.31    369112\n",
      "weighted avg       0.74      0.86      0.80    369112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MLP classifier on top of BERT embeddings\n",
    "clf = SGDClassifier(loss=\"log_loss\", max_iter=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "# Predict\n",
    "y_pred = clf.predict(X_test)\n",
    "# Evaluate\n",
    "print(\"BERT Embeddings + MLP Performance:\")\n",
    "print(classification_report(y_test, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5d4412-bef4-43bd-a02c-03307a3ef8af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
