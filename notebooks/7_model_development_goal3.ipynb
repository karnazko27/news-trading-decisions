{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_NpKfhrdAAcw",
    "outputId": "c3248507-f9ae-46aa-ad41-b4a988bfd5a8"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YwxN3NloAQ9I",
    "outputId": "60d814f4-e1bc-4e21-8884-a5921e7badc2"
   },
   "outputs": [],
   "source": [
    "# cd drive/MyDrive/IE7500_GroupB/Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BektPtZ7P28Y",
    "outputId": "a0f390f5-5872-4d3e-cd2a-b8741974ded9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ensorflow (/courses/IE7500.202530/shared/conda_env_1/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: xgboost in /home/obaidullah.k/.local/lib/python3.12/site-packages (3.0.0)\n",
      "Requirement already satisfied: numpy in /courses/IE7500.202530/shared/conda_env_1/lib/python3.12/site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: nvidia-nccl-cu12 in /courses/IE7500.202530/shared/conda_env_1/lib/python3.12/site-packages (from xgboost) (2.23.4)\n",
      "Requirement already satisfied: scipy in /courses/IE7500.202530/shared/conda_env_1/lib/python3.12/site-packages (from xgboost) (1.13.1)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ensorflow (/courses/IE7500.202530/shared/conda_env_1/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ensorflow (/courses/IE7500.202530/shared/conda_env_1/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "Collecting lightgbm\n",
      "  Downloading lightgbm-4.6.0-py3-none-manylinux_2_28_x86_64.whl.metadata (17 kB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /courses/IE7500.202530/shared/conda_env_1/lib/python3.12/site-packages (from lightgbm) (1.26.4)\n",
      "Requirement already satisfied: scipy in /courses/IE7500.202530/shared/conda_env_1/lib/python3.12/site-packages (from lightgbm) (1.13.1)\n",
      "Downloading lightgbm-4.6.0-py3-none-manylinux_2_28_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ensorflow (/courses/IE7500.202530/shared/conda_env_1/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: lightgbm\n",
      "Successfully installed lightgbm-4.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "oqumQnWisnKT"
   },
   "outputs": [],
   "source": [
    "# load necesary libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "sEjjuVU-s-vW"
   },
   "outputs": [],
   "source": [
    "dtypes_dict = {'headline': 'object',\n",
    "               'url': 'object',\n",
    "               'publisher': 'object',\n",
    "               'stock': 'object',\n",
    "               'tokens': 'object',\n",
    "               'normalized_tokens': 'object',\n",
    "               'filtered_tokens': 'object',\n",
    "               'lemmas': 'object',\n",
    "               'sentiment_score': 'float64',\n",
    "               'Name': 'object',\n",
    "               'Market Cap': 'float64',\n",
    "               'Country': 'object',\n",
    "               'IPO Year': 'float64',\n",
    "               'Sector': 'object',\n",
    "               'Industry': 'object',\n",
    "               'year': 'int32',\n",
    "               'month': 'int32',\n",
    "               'day_of_week': 'int32',\n",
    "               'sentiment_label': 'int64',\n",
    "               'headline_length': 'int64',\n",
    "               'word_count': 'int64',\n",
    "               'Market_Cap_Category': 'object',\n",
    "               'recommendation': 'object',\n",
    "               'cap_Large': 'bool',\n",
    "               'cap_Medium': 'bool',\n",
    "               'cap_Mega': 'bool',\n",
    "               'cap_Micro': 'bool',\n",
    "               'cap_Nano': 'bool',\n",
    "               'cap_Small': 'bool',\n",
    "               'sector_Basic Materials': 'bool',\n",
    "               'sector_Consumer Discretionary': 'bool',\n",
    "               'sector_Consumer Staples': 'bool',\n",
    "               'sector_Energy': 'bool',\n",
    "               'sector_Finance': 'bool',\n",
    "               'sector_Health Care': 'bool',\n",
    "               'sector_Industrials': 'bool',\n",
    "               'sector_Miscellaneous': 'bool',\n",
    "               'sector_Real Estate': 'bool',\n",
    "               'sector_Technology': 'bool',\n",
    "               'sector_Telecommunications': 'bool',\n",
    "               'sector_Utilities': 'bool', 'recommendation_label': 'int64',\n",
    "               'publisher_label': 'int64', 'country_label': 'int64',\n",
    "               'industry_label': 'int64'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "tX9BQsylAqtr"
   },
   "outputs": [],
   "source": [
    "# load dataframes to use\n",
    "df_main = pd.read_csv(\"saved_dfs/df_for_models.csv\", dtype=dtypes_dict,\n",
    "                      parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 602
    },
    "id": "RSVPzNEBAqrU",
    "outputId": "4105b754-484a-4aac-b24f-a67583901658"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>url</th>\n",
       "      <th>publisher</th>\n",
       "      <th>date</th>\n",
       "      <th>stock</th>\n",
       "      <th>tokens</th>\n",
       "      <th>normalized_tokens</th>\n",
       "      <th>filtered_tokens</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>...</th>\n",
       "      <th>sector_Industrials</th>\n",
       "      <th>sector_Miscellaneous</th>\n",
       "      <th>sector_Real Estate</th>\n",
       "      <th>sector_Technology</th>\n",
       "      <th>sector_Telecommunications</th>\n",
       "      <th>sector_Utilities</th>\n",
       "      <th>recommendation_label</th>\n",
       "      <th>publisher_label</th>\n",
       "      <th>country_label</th>\n",
       "      <th>industry_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agilent Technologies Announces Pricing of $5……...</td>\n",
       "      <td>http://www.gurufocus.com/news/1153187/agilent-...</td>\n",
       "      <td>GuruFocus</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>A</td>\n",
       "      <td>['Agilent', 'Technologies', 'Announces', 'Pric...</td>\n",
       "      <td>['agilent', 'technologies', 'announces', 'pric...</td>\n",
       "      <td>['agilent', 'technologies', 'announces', 'pric...</td>\n",
       "      <td>['agilent', 'technology', 'announces', 'pricin...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Agilent (A) Gears Up for Q2 Earnings: What's i...</td>\n",
       "      <td>http://www.zacks.com/stock/news/931205/agilent...</td>\n",
       "      <td>Zacks</td>\n",
       "      <td>2020-05-18</td>\n",
       "      <td>A</td>\n",
       "      <td>['Agilent', '(', 'A', ')', 'Gears', 'Up', 'for...</td>\n",
       "      <td>['agilent', 'a', 'gears', 'up', 'for', 'q2', '...</td>\n",
       "      <td>['agilent', 'gears', 'q2', 'earnings', 'cards']</td>\n",
       "      <td>['agilent', 'gear', 'q2', 'earnings', 'card']</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>45</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>J.P. Morgan Asset Management Announces Liquida...</td>\n",
       "      <td>http://www.gurufocus.com/news/1138923/jp-morga...</td>\n",
       "      <td>GuruFocus</td>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>A</td>\n",
       "      <td>['J.P.', 'Morgan', 'Asset', 'Management', 'Ann...</td>\n",
       "      <td>['morgan', 'asset', 'management', 'announces',...</td>\n",
       "      <td>['morgan', 'asset', 'management', 'announces',...</td>\n",
       "      <td>['morgan', 'asset', 'management', 'announces',...</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pershing Square Capital Management, L.P. Buys ...</td>\n",
       "      <td>http://www.gurufocus.com/news/1138704/pershing...</td>\n",
       "      <td>GuruFocus</td>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>A</td>\n",
       "      <td>['Pershing', 'Square', 'Capital', 'Management'...</td>\n",
       "      <td>['pershing', 'square', 'capital', 'management'...</td>\n",
       "      <td>['pershing', 'square', 'capital', 'management'...</td>\n",
       "      <td>['pershing', 'square', 'capital', 'management'...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Agilent Awards Trilogy Sciences with a Golden ...</td>\n",
       "      <td>http://www.gurufocus.com/news/1134012/agilent-...</td>\n",
       "      <td>GuruFocus</td>\n",
       "      <td>2020-05-12</td>\n",
       "      <td>A</td>\n",
       "      <td>['Agilent', 'Awards', 'Trilogy', 'Sciences', '...</td>\n",
       "      <td>['agilent', 'awards', 'trilogy', 'sciences', '...</td>\n",
       "      <td>['agilent', 'awards', 'trilogy', 'sciences', '...</td>\n",
       "      <td>['agilent', 'award', 'trilogy', 'science', 'go...</td>\n",
       "      <td>0.4588</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  \\\n",
       "0  Agilent Technologies Announces Pricing of $5……...   \n",
       "1  Agilent (A) Gears Up for Q2 Earnings: What's i...   \n",
       "2  J.P. Morgan Asset Management Announces Liquida...   \n",
       "3  Pershing Square Capital Management, L.P. Buys ...   \n",
       "4  Agilent Awards Trilogy Sciences with a Golden ...   \n",
       "\n",
       "                                                 url  publisher       date  \\\n",
       "0  http://www.gurufocus.com/news/1153187/agilent-...  GuruFocus 2020-06-01   \n",
       "1  http://www.zacks.com/stock/news/931205/agilent...      Zacks 2020-05-18   \n",
       "2  http://www.gurufocus.com/news/1138923/jp-morga...  GuruFocus 2020-05-15   \n",
       "3  http://www.gurufocus.com/news/1138704/pershing...  GuruFocus 2020-05-15   \n",
       "4  http://www.gurufocus.com/news/1134012/agilent-...  GuruFocus 2020-05-12   \n",
       "\n",
       "  stock                                             tokens  \\\n",
       "0     A  ['Agilent', 'Technologies', 'Announces', 'Pric...   \n",
       "1     A  ['Agilent', '(', 'A', ')', 'Gears', 'Up', 'for...   \n",
       "2     A  ['J.P.', 'Morgan', 'Asset', 'Management', 'Ann...   \n",
       "3     A  ['Pershing', 'Square', 'Capital', 'Management'...   \n",
       "4     A  ['Agilent', 'Awards', 'Trilogy', 'Sciences', '...   \n",
       "\n",
       "                                   normalized_tokens  \\\n",
       "0  ['agilent', 'technologies', 'announces', 'pric...   \n",
       "1  ['agilent', 'a', 'gears', 'up', 'for', 'q2', '...   \n",
       "2  ['morgan', 'asset', 'management', 'announces',...   \n",
       "3  ['pershing', 'square', 'capital', 'management'...   \n",
       "4  ['agilent', 'awards', 'trilogy', 'sciences', '...   \n",
       "\n",
       "                                     filtered_tokens  \\\n",
       "0  ['agilent', 'technologies', 'announces', 'pric...   \n",
       "1    ['agilent', 'gears', 'q2', 'earnings', 'cards']   \n",
       "2  ['morgan', 'asset', 'management', 'announces',...   \n",
       "3  ['pershing', 'square', 'capital', 'management'...   \n",
       "4  ['agilent', 'awards', 'trilogy', 'sciences', '...   \n",
       "\n",
       "                                              lemmas  sentiment_score  ...  \\\n",
       "0  ['agilent', 'technology', 'announces', 'pricin...           0.0000  ...   \n",
       "1      ['agilent', 'gear', 'q2', 'earnings', 'card']           0.0000  ...   \n",
       "2  ['morgan', 'asset', 'management', 'announces',...           0.3612  ...   \n",
       "3  ['pershing', 'square', 'capital', 'management'...           0.0000  ...   \n",
       "4  ['agilent', 'award', 'trilogy', 'science', 'go...           0.4588  ...   \n",
       "\n",
       "  sector_Industrials  sector_Miscellaneous sector_Real Estate  \\\n",
       "0               True                 False              False   \n",
       "1               True                 False              False   \n",
       "2               True                 False              False   \n",
       "3               True                 False              False   \n",
       "4               True                 False              False   \n",
       "\n",
       "   sector_Technology sector_Telecommunications sector_Utilities  \\\n",
       "0              False                     False            False   \n",
       "1              False                     False            False   \n",
       "2              False                     False            False   \n",
       "3              False                     False            False   \n",
       "4              False                     False            False   \n",
       "\n",
       "   recommendation_label  publisher_label  country_label  industry_label  \n",
       "0                     1                4             45              18  \n",
       "1                     1               16             45              18  \n",
       "2                     1                4             45              18  \n",
       "3                     1                4             45              18  \n",
       "4                     1                4             45              18  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_main.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Fh0GUFUpeCN"
   },
   "source": [
    "# Goal 3: ML Trading Bot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-20 15:42:53.528054: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745178173.548573 1303934 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745178173.554777 1303934 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1745178173.571206 1303934 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745178173.571221 1303934 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745178173.571224 1303934 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745178173.571226 1303934 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-20 15:42:53.577279: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# === GOAL 3: Setup for NLP-Based Trading Bot Models ===\n",
    "\n",
    "# 1. Define text and target\n",
    "text_column = 'headline'\n",
    "X_text = df_main[text_column].fillna('').astype(str)\n",
    "y = df_main['recommendation_label']\n",
    "\n",
    "# 2. Train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
    "    X_text, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# 3. Optional structured features for hybrid models\n",
    "structured_features = [\n",
    "    'sentiment_score', 'headline_length', 'word_count',\n",
    "    'cap_Large', 'cap_Medium', 'cap_Small',\n",
    "    'sector_Technology', 'sector_Finance', 'sector_Health Care'\n",
    "]\n",
    "\n",
    "X_structured = df_main[structured_features]\n",
    "X_train_struct, X_test_struct = train_test_split(\n",
    "    X_structured, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# 4. TF-IDF vectorization (for MLP or XGBoost)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_vec = vectorizer.fit_transform(X_train_text)\n",
    "X_test_vec = vectorizer.transform(X_test_text)\n",
    "\n",
    "# 5. Tokenizer (for LSTM)\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train_text)\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train_text)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test_text)\n",
    "max_len = 30\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len, padding=\"post\")\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len, padding=\"post\")\n",
    "\n",
    "# 6. One-hot encode labels (for Keras models)\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train_cat = to_categorical(y_train)\n",
    "y_test_cat = to_categorical(y_test)\n",
    "num_classes = y_train_cat.shape[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i6skcy4upg6D"
   },
   "source": [
    "## Method 1: XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Performance on Headlines:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.55      0.69     36913\n",
      "           1       0.93      0.99      0.96    317698\n",
      "           2       0.92      0.40      0.55     14501\n",
      "\n",
      "    accuracy                           0.93    369112\n",
      "   macro avg       0.92      0.65      0.73    369112\n",
      "weighted avg       0.93      0.93      0.92    369112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "xgb_pipeline = Pipeline([\n",
    "    (\"clf\", XGBClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=5,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        eval_metric=\"mlogloss\",\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "xgb_pipeline.fit(X_train_vec, y_train)\n",
    "\n",
    "y_pred_xgb = xgb_pipeline.predict(X_test_vec)\n",
    "print(\"XGBoost Performance on Headlines:\")\n",
    "print(classification_report(y_test, y_pred_xgb, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x3B5koRqt6eD"
   },
   "source": [
    "## Method 2: LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 2.724529 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 280221\n",
      "[LightGBM] [Info] Number of data points in the train set: 1476447, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score -2.302549\n",
      "[LightGBM] [Info] Start training from score -0.149999\n",
      "[LightGBM] [Info] Start training from score -3.236847\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define and train fine-tuned LightGBM model\n",
    "lgbm_model = LGBMClassifier(\n",
    "    objective=\"multiclass\",\n",
    "    num_class=3,\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    num_leaves=31,\n",
    "    min_child_samples=20,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=0.3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "lgbm_model.fit(\n",
    "    X_train_vec, y_train,\n",
    "    eval_set=[(X_test_vec, y_test)],\n",
    "    eval_metric=\"multi_logloss\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/courses/IE7500.202530/shared/conda_env_1/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Classifier Performance on Headlines:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.66      0.77     36913\n",
      "           1       0.94      0.99      0.97    317698\n",
      "           2       0.91      0.58      0.71     14501\n",
      "\n",
      "    accuracy                           0.94    369112\n",
      "   macro avg       0.93      0.75      0.82    369112\n",
      "weighted avg       0.94      0.94      0.94    369112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict and evaluate\n",
    "y_pred_lgbm = lgbm_model.predict(X_test_vec)\n",
    "print(\"LightGBM Classifier Performance on Headlines:\")\n",
    "print(classification_report(y_test, y_pred_lgbm, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 3: FinBERT + SGDClassifier for Trading Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution ~ensorflow (/courses/IE7500.202530/shared/conda_env_1/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ensorflow (/courses/IE7500.202530/shared/conda_env_1/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name yiyanghkust/finbert-tone. Creating a new one with mean pooling.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Batches:   1%|          | 325/46139 [02:16<5:21:03,  2.38it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m SentenceTransformer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myiyanghkust/finbert-tone\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# 3. Encode headlines (X_train_text and X_test_text from setup)\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m X_train_finbert \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_text\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m X_test_finbert \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode(X_test_text\u001b[38;5;241m.\u001b[39mtolist(), batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, show_progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# 4. Train classifier\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py:685\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    682\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate(extra_features)\n\u001b[1;32m    684\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 685\u001b[0m     out_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhpu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    687\u001b[0m         out_features \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(out_features)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py:753\u001b[0m, in \u001b[0;36mSentenceTransformer.forward\u001b[0;34m(self, input, **kwargs)\u001b[0m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Tensor], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Tensor]:\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 753\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    755\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module_name, module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnamed_children():\n\u001b[1;32m    756\u001b[0m         module_kwarg_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_kwargs\u001b[38;5;241m.\u001b[39mget(module_name, [])\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sentence_transformers/models/Transformer.py:442\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, features, **kwargs)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns token_embeddings, cls_token\"\"\"\u001b[39;00m\n\u001b[1;32m    436\u001b[0m trans_features \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    437\u001b[0m     key: value\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m features\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs_embeds\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    440\u001b[0m }\n\u001b[0;32m--> 442\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauto_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrans_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m token_embeddings \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    444\u001b[0m features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m token_embeddings\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/courses/IE7500.202530/shared/conda_env_1/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1142\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m   1140\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m-> 1142\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1154\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1155\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/courses/IE7500.202530/shared/conda_env_1/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:695\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    684\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    685\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    686\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    692\u001b[0m         output_attentions,\n\u001b[1;32m    693\u001b[0m     )\n\u001b[1;32m    694\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 695\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/courses/IE7500.202530/shared/conda_env_1/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:585\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    574\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    575\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    582\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    584\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 585\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    592\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/courses/IE7500.202530/shared/conda_env_1/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:515\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    507\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    513\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    514\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m--> 515\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    524\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[1;32m    525\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/courses/IE7500.202530/shared/conda_env_1/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:440\u001b[0m, in \u001b[0;36mBertSdpaSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;66;03m# We dispatch to SDPA's Flash Attention or Efficient kernels via this `is_causal` if statement instead of an inline conditional assignment\u001b[39;00m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;66;03m# in SDPA to support both torch.compile's dynamic shapes and full graph options. An inline conditional prevents dynamic shapes from compiling.\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;66;03m# The tgt_len > 1 is necessary to match with AttentionMaskConverter.to_causal_4d that does not create\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;66;03m# a causal mask in case tgt_len == 1.\u001b[39;00m\n\u001b[1;32m    436\u001b[0m is_causal \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_decoder \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cross_attention \u001b[38;5;129;01mand\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m tgt_len \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    438\u001b[0m )\n\u001b[0;32m--> 440\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaled_dot_product_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout_prob\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    449\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    450\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mreshape(bsz, tgt_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_head_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 2. Load sentence-transformers FinBERT (optimized for speed)\n",
    "model = SentenceTransformer(\"yiyanghkust/finbert-tone\")\n",
    "\n",
    "# 3. Encode headlines (X_train_text and X_test_text from setup)\n",
    "X_train_finbert = model.encode(X_train_text.tolist(), batch_size=32, show_progress_bar=True)\n",
    "X_test_finbert = model.encode(X_test_text.tolist(), batch_size=32, show_progress_bar=True)\n",
    "\n",
    "# 4. Train classifier\n",
    "clf = SGDClassifier(loss=\"log_loss\", max_iter=1000, random_state=42)\n",
    "clf.fit(X_train_finbert, y_train)\n",
    "\n",
    "# 5. Predict and evaluate\n",
    "y_pred = clf.predict(X_test_finbert)\n",
    "print(\"FinBERT (sentence-transformers) + SGDClassifier Performance:\")\n",
    "print(classification_report(y_test, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Map predictions to trade actions\n",
    "def map_to_action(pred):\n",
    "    return {0: \"SELL\", 1: \"HOLD\", 2: \"BUY\"}.get(pred, \"UNKNOWN\")\n",
    "\n",
    "actions = [map_to_action(p) for p in y_pred]\n",
    "print(\"Predicted trade actions:\", actions[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1. Load FinBERT (pretrained by ProsusAI or ipuneetrathore)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
    "model = AutoModel.from_pretrained(\"ProsusAI/finbert\")\n",
    "model.eval()\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# 2. Batched FinBERT encoding\n",
    "def finbert_encode_batched(texts, tokenizer, model, batch_size=32, max_len=30):\n",
    "    all_embeddings = []\n",
    "\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Encoding with FinBERT\"):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        encoded = tokenizer(batch_texts, return_tensors='pt', padding=True, truncation=True, max_length=max_len)\n",
    "        encoded = {k: v.to(device) for k, v in encoded.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**encoded)\n",
    "            cls_embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "            all_embeddings.append(cls_embeddings.cpu().numpy())\n",
    "\n",
    "    return np.vstack(all_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding with FinBERT: 100%|██████████| 46139/46139 [1:56:27<00:00,  6.60it/s]  \n",
      "Encoding with FinBERT: 100%|██████████| 11535/11535 [28:32<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FinBERT + SGDClassifier Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.27      0.39     36913\n",
      "           1       0.89      0.99      0.94    317698\n",
      "           2       0.83      0.26      0.40     14501\n",
      "\n",
      "    accuracy                           0.89    369112\n",
      "   macro avg       0.81      0.51      0.58    369112\n",
      "weighted avg       0.87      0.89      0.86    369112\n",
      "\n",
      "Predicted trade actions: ['HOLD', 'HOLD', 'HOLD', 'HOLD', 'HOLD', 'HOLD', 'HOLD', 'HOLD', 'HOLD', 'HOLD']\n"
     ]
    }
   ],
   "source": [
    "# 3. Encode headlines\n",
    "X_train_finbert = finbert_encode_batched(X_train_text.tolist(), tokenizer, model)\n",
    "X_test_finbert = finbert_encode_batched(X_test_text.tolist(), tokenizer, model)\n",
    "\n",
    "# 4. Train SGDClassifier\n",
    "clf = SGDClassifier(loss=\"log_loss\", max_iter=1000, random_state=42)\n",
    "clf.fit(X_train_finbert, y_train)\n",
    "\n",
    "# 5. Predict and evaluate\n",
    "y_pred = clf.predict(X_test_finbert)\n",
    "print(\"FinBERT + SGDClassifier Performance:\")\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "# 6. Map predictions to actions\n",
    "def map_to_action(pred):\n",
    "    return {0: \"SELL\", 1: \"HOLD\", 2: \"BUY\"}.get(pred, \"UNKNOWN\")\n",
    "\n",
    "print(\"Predicted trade actions:\", [map_to_action(p) for p in y_pred[:10]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "689afI3IvKDw"
   },
   "source": [
    "## Method 4: Reinforcement Learning (DQN) for ML Trading Bot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "qT7FPs-tuUgK",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "656735a9-7101-42d5-b4a0-5255f2a68ee7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
      "Collecting stable-baselines3[extra]\n",
      "  Downloading stable_baselines3-2.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting gymnasium<1.1.0,>=0.29.1 (from stable-baselines3[extra])\n",
      "  Downloading gymnasium-1.0.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.0.2)\n",
      "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.6.0+cu124)\n",
      "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (3.1.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.2.2)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (3.10.0)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (4.11.0.86)\n",
      "Requirement already satisfied: pygame in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.6.1)\n",
      "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.18.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (5.9.5)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (4.67.1)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (13.9.4)\n",
      "Requirement already satisfied: ale-py>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (0.10.2)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (11.1.0)\n",
      "Requirement already satisfied: gym_notices>=0.0.4 in /usr/local/lib/python3.11/dist-packages (from gym) (0.0.8)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.1.0,>=0.29.1->stable-baselines3[extra]) (4.12.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.1.0,>=0.29.1->stable-baselines3[extra]) (0.0.4)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.71.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.7)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (5.29.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (75.1.0)\n",
      "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.17.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.1.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.18.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (2025.3.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable-baselines3[extra]) (1.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3[extra]) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3[extra]) (2025.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->stable-baselines3[extra]) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->stable-baselines3[extra]) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.2)\n",
      "Downloading gymnasium-1.0.0-py3-none-any.whl (958 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m958.1/958.1 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading stable_baselines3-2.5.0-py3-none-any.whl (183 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, gymnasium, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, stable-baselines3\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: gymnasium\n",
      "    Found existing installation: gymnasium 1.1.1\n",
      "    Uninstalling gymnasium-1.1.1:\n",
      "      Successfully uninstalled gymnasium-1.1.1\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed gymnasium-1.0.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 stable-baselines3-2.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install stable-baselines3[extra] gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "W_K8PqTcuUdZ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gym\n",
    "from gym import spaces\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "# Features for the RL environment\n",
    "features = [\"sentiment_score\", \"publisher_label\", \"country_label\", \"industry_label\",\n",
    "            \"sector_Industrials\", \"sector_Miscellaneous\", \"sector_Real Estate\",\n",
    "            \"sector_Technology\", \"sector_Telecommunications\", \"sector_Utilities\"]\n",
    "\n",
    "# Prepare feature data\n",
    "rl_df = df_main[features].fillna(0).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "7525QwKCuUat"
   },
   "outputs": [],
   "source": [
    "class TradingEnv(gym.Env):\n",
    "    def __init__(self, df):\n",
    "        super(TradingEnv, self).__init__()\n",
    "        self.df = df\n",
    "        self.current_step = 0\n",
    "        self.initial_balance = 1000.0\n",
    "        self.balance = self.initial_balance\n",
    "        self.shares_held = 0\n",
    "        self.n_steps = len(df)\n",
    "\n",
    "        # Actions: 0 = Hold, 1 = Buy, 2 = Sell\n",
    "        self.action_space = spaces.Discrete(3)\n",
    "        # Observations: all features (shape = number of columns)\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(df.shape[1],), dtype=np.float32)\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        self.balance = self.initial_balance\n",
    "        self.shares_held = 0\n",
    "        return self.df.iloc[self.current_step].values.astype(np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        done = False\n",
    "        current_price = self.df.iloc[self.current_step][\"sentiment_score\"] + 1  # Simulated price\n",
    "        reward = 0\n",
    "\n",
    "        # Execute Buy\n",
    "        if action == 1 and self.balance >= current_price:\n",
    "            self.shares_held += 1\n",
    "            self.balance -= current_price\n",
    "        # Execute Sell\n",
    "        elif action == 2 and self.shares_held > 0:\n",
    "            self.shares_held -= 1\n",
    "            self.balance += current_price\n",
    "            reward = current_price - 1  # Assume base cost = 1\n",
    "\n",
    "        # Go to next step\n",
    "        self.current_step += 1\n",
    "        if self.current_step >= self.n_steps - 1:\n",
    "            done = True\n",
    "\n",
    "        obs = self.df.iloc[self.current_step].values.astype(np.float32)\n",
    "        return obs, reward, done, {}\n",
    "\n",
    "    def render(self, mode=\"human\"):\n",
    "        print(f\"Step: {self.current_step}, Balance: {self.balance:.2f}, Shares: {self.shares_held}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gQZQAC7BwGli",
    "outputId": "3db8f5ac-7f58-4e0c-c87e-c628cbd5ad0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting shimmy>=2.0\n",
      "  Downloading Shimmy-2.0.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from shimmy>=2.0) (2.0.2)\n",
      "Requirement already satisfied: gymnasium>=1.0.0a1 in /usr/local/lib/python3.11/dist-packages (from shimmy>=2.0) (1.0.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0a1->shimmy>=2.0) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0a1->shimmy>=2.0) (4.12.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0a1->shimmy>=2.0) (0.0.4)\n",
      "Downloading Shimmy-2.0.0-py3-none-any.whl (30 kB)\n",
      "Installing collected packages: shimmy\n",
      "Successfully installed shimmy-2.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install 'shimmy>=2.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iQ9TpNT2uUYI",
    "outputId": "152862a1-0f03-4b59-ab40-5cc829e804bc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Wrap the custom environment using DummyVecEnv\n",
    "env = DummyVecEnv([lambda: TradingEnv(rl_df)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X9Vb5b6Qvd0C",
    "outputId": "6779666c-e303-4ad3-f036-fa869be0b780"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.dqn.dqn.DQN at 0x780eea910150>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and train the DQN agent\n",
    "model = DQN(\"MlpPolicy\", env, verbose=1)\n",
    "model.learn(total_timesteps=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "53oGAWoivdw6",
    "outputId": "a079622d-81bd-412f-9ea4-0f9efe8f72cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Reward from DQN Agent: [20697.22]\n"
     ]
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "total_reward = 0\n",
    "\n",
    "for _ in range(len(rl_df) - 1):\n",
    "    action, _ = model.predict(obs)\n",
    "    obs, reward, done, _ = env.step(action)\n",
    "    total_reward += reward\n",
    "    if done:\n",
    "        break\n",
    "\n",
    "print(f\"Total Reward from DQN Agent: {total_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P0ChLWW9vdls",
    "outputId": "21bad944-53b8-421e-9b48-db6e7c264a0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as dqn_trading_bot.zip\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save(\"dqn_trading_bot\")\n",
    "print(\"Model saved as dqn_trading_bot.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S8xFAC8PvxRW"
   },
   "source": [
    "## Method 5: LSTM for Time Series Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "N0-icVxvvdik"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, GRU, Dense\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "_Y8kb6a7vdfP"
   },
   "outputs": [],
   "source": [
    "# Use sentiment_score as proxy for \"price\" or signal\n",
    "data = df_main[\"sentiment_score\"].fillna(0).values.reshape(-1, 1)\n",
    "\n",
    "# Scale data between 0 and 1\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "# Create sequences for supervised learning\n",
    "def create_sequences(data, seq_len=10):\n",
    "    X, y = [], []\n",
    "    for i in range(seq_len, len(data)):\n",
    "        X.append(data[i-seq_len:i])\n",
    "        y.append(data[i])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "sequence_length = 10\n",
    "X_seq, y_seq = create_sequences(scaled_data, sequence_length)\n",
    "\n",
    "# Split into training and test sets (80/20)\n",
    "split_idx = int(0.8 * len(X_seq))\n",
    "X_train, X_test = X_seq[:split_idx], X_seq[split_idx:]\n",
    "y_train, y_test = y_seq[:split_idx], y_seq[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254
    },
    "id": "7OYlIil8vdcU",
    "outputId": "94db7607-cef4-4ff9-e325-1d41746486b8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m16,896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m65\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,961</span> (66.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m16,961\u001b[0m (66.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,961</span> (66.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m16,961\u001b[0m (66.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build LSTM model\n",
    "lstm_model = Sequential([\n",
    "    LSTM(64, input_shape=(X_train.shape[1], 1)),\n",
    "    Dense(1)\n",
    "])\n",
    "lstm_model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "md31_04SvdZt",
    "outputId": "384f7c34-782a-475c-88ee-430893f16f72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m46139/46139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m346s\u001b[0m 7ms/step - loss: 0.0225 - val_loss: 0.0232\n",
      "Epoch 2/5\n",
      "\u001b[1m46139/46139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m370s\u001b[0m 7ms/step - loss: 0.0224 - val_loss: 0.0232\n",
      "Epoch 3/5\n",
      "\u001b[1m46139/46139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 7ms/step - loss: 0.0224 - val_loss: 0.0231\n",
      "Epoch 4/5\n",
      "\u001b[1m46139/46139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m344s\u001b[0m 7ms/step - loss: 0.0224 - val_loss: 0.0232\n",
      "Epoch 5/5\n",
      "\u001b[1m46139/46139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 7ms/step - loss: 0.0224 - val_loss: 0.0232\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x780d72e10b50>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train LSTM model, use 5 epochs to save time\n",
    "lstm_model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5n6Vt_55vdW3",
    "outputId": "ee708cb8-8f4a-4229-c0b4-ac995a8bea7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11535/11535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 3ms/step\n",
      "LSTM Test RMSE: 0.2905\n"
     ]
    }
   ],
   "source": [
    "# Predict on test data\n",
    "y_pred = lstm_model.predict(X_test)\n",
    "\n",
    "# Inverse scale predictions and ground truth\n",
    "y_pred_inv = scaler.inverse_transform(y_pred)\n",
    "y_test_inv = scaler.inverse_transform(y_test)\n",
    "\n",
    "# Compute RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test_inv, y_pred_inv))\n",
    "print(f\"LSTM Test RMSE: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "nIdgz8odvdUS",
    "outputId": "68e0599e-8ea7-45d7-e910-b98dc1535258"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAksAAAHHCAYAAACvJxw8AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAtupJREFUeJzs3XdcE/cbB/DPZQIiSxmiKIh7WwfOuqg4Wnedde9Z67Zurdtat9atVevWn9sqbsWFdY+Ke4GKAiJKSHK/P5CYebnLIEGf9+uVVi43vll3z33H82VYlmVBCCGEEEKMEjm6AIQQQgghzoyCJUIIIYQQDhQsEUIIIYRwoGCJEEIIIYQDBUuEEEIIIRwoWCKEEEII4UDBEiGEEEIIBwqWCCGEEEI4ULBECCGEEMKBgiVCSJY1fvx4MAzj6GI4vYcPH4JhGKxevdrRRSEkS6JgiXzRVq9eDYZhcPHiRc71Xr16hZ9//hlFihSBq6sr/Pz8ULFiRQwfPhzJyck4duwYGIbh9dA+LsMwOHXqlMHxWJZFUFAQGIbB999/b/Z11KxZ0+Txbt++bdmbk0WkpKRg/PjxOHbsmKOLwotCocDcuXNRtmxZeHh4wMvLC8WLF0ePHj3s/llt2LABc+bMsesx7Gnfvn0YP3487/XVajXWrl2LsLAw+Pj4IHv27ChUqBA6dOiAs2fP2q+g5KsjcXQBCHG0N2/eoHz58khKSkKXLl1QpEgRxMfH4+rVq1i8eDF69+6NokWL4q+//tLZbuTIkXB3d8eoUaNM7tvFxQUbNmxAtWrVdJYfP34cT58+hVwu513OPHnyYOrUqQbLAwMDee8jK0pJScGECRMApAeN2kaPHo0RI0Y4oFSmNW/eHPv370ebNm3QvXt3pKWl4fbt29izZw+qVKmCIkWK2O3YGzZswPXr1zFw4ECd5fny5cOHDx8glUrtdmxb2LdvHxYuXMg7YBowYAAWLlyIxo0bo127dpBIJLhz5w7279+P/Pnzo1KlSvYtMPlqULBEvnorVqzA48ePcfr0aVSpUkXnuaSkJMhkMri4uOCnn37SeW7atGnImTOnwXJtDRo0wJYtWzBv3jxIJJ9/bhs2bEC5cuXw+vVr3uX09PTkPJalWJbFx48f4erqavN925tEItF5Xx3twoUL2LNnDyZPnoxff/1V57kFCxYgISHBIeViGAYuLi4OOba9xMXFYdGiRejevTuWLl2q89ycOXPw6tWrTCuLUqmEWq2GTCbLtGOSzEXNcOSrd+/ePYjFYqN3oR4eHlZdZNq0aYP4+HgcOnRIs0yhUGDr1q1o27atxfs1RqlUYtKkSQgNDYVcLkdwcDB+/fVXpKam6qwXHByM77//HgcPHkT58uXh6uqKP//8EwCQkJCAgQMHIigoCHK5HAUKFMD06dOhVqt19qFWqzF37lyULFkSLi4u8PX1Rb169XSaO1etWoXatWvDz88PcrkcxYoVw+LFiw3KffHiRURERCBnzpxwdXVFSEgIunTpAiC9r42vry8AYMKECZqmx4yaB2N9lhiGQb9+/bBz506UKFECcrkcxYsXx4EDBwyOfezYMZQvXx4uLi4IDQ3Fn3/+aXSfr1+/xu3bt5GSksL5Gdy7dw8AULVqVYPnxGIxcuTIobPs2bNn6NKlC/z9/TXlXLlypUEZGYbB5s2bMXnyZOTJkwcuLi6oU6cOYmJiNOvVrFkTe/fuxaNHjzTvU3BwsOZ91O+z1KlTJ7i7u+Px48f4/vvv4e7ujty5c2PhwoUAgGvXrqF27drIli0b8uXLhw0bNhi8Jj7fl4xjz5o1C0uXLtV8PytUqIALFy7olCfj2PrN2sY8ePAALMsafa8ZhoGfn59BWX/55RcEBwdDLpcjT5486NChg84Ny8uXL9G1a1f4+/vDxcUFpUuXxpo1a3T2o/165syZo3k9N2/eBADcvn0bLVq0gI+PD1xcXFC+fHns2rXL5OsgWYPz3JIR4iD58uWDSqXCX3/9hY4dO9p038HBwahcuTL+/vtv1K9fHwCwf/9+JCYmonXr1pg3bx7vfalUKoOaKBcXF7i7uwMAunXrhjVr1qBFixYYPHgwzp07h6lTp+LWrVvYsWOHznZ37txBmzZt0LNnT3Tv3h2FCxdGSkoKatSogWfPnqFnz57Imzcvzpw5g5EjR+LFixc6fWG6du2K1atXo379+ujWrRuUSiVOnjyJs2fPonz58gCAxYsXo3jx4mjUqBEkEgl2796NPn36QK1Wo2/fvgDSL05169aFr68vRowYAS8vLzx8+BDbt28HAPj6+mqaQps2bYpmzZoBAEqVKsX5Xp06dQrbt29Hnz59kD17dsybNw/NmzfH48ePNQHLv//+i3r16iFXrlyYMGECVCoVJk6cqAnOtC1YsAATJkzA0aNHDZoCteXLlw8AsH79elStWpWz1isuLg6VKlXSBHe+vr7Yv38/unbtiqSkJIOmtGnTpkEkEmHIkCFITEzEjBkz0K5dO5w7dw4AMGrUKCQmJuLp06f4448/AEDz3TBFpVKhfv36+PbbbzFjxgysX78e/fr1Q7Zs2TBq1Ci0a9cOzZo1w5IlS9ChQwdUrlwZISEhACDo+wKk16a+e/cOPXv2BMMwmDFjBpo1a4b79+9DKpWiZ8+eeP78OQ4dOmTQ5M31Xm/ZsgU//vgj3NzcTK6bnJyM6tWr49atW+jSpQu++eYbvH79Grt27cLTp0+RM2dOfPjwATVr1kRMTAz69euHkJAQbNmyBZ06dUJCQgJ+/vlnnX2uWrUKHz9+RI8ePSCXy+Hj44MbN26gatWqyJ07N0aMGIFs2bJh8+bNaNKkCbZt24amTZuafV3ESbGEfMFWrVrFAmAvXLhgcp3Y2FjW19eXBcAWKVKE7dWrF7thwwY2ISGBc9/Fixdna9SoYfa4CxYsYLNnz86mpKSwLMuyP/74I1urVi2WZVk2X758bMOGDc2+jho1arAADB4dO3ZkWZZlL1++zAJgu3XrprPdkCFDWADskSNHNMvy5cvHAmAPHDigs+6kSZPYbNmysf/995/O8hEjRrBisZh9/Pgxy7Ise+TIERYAO2DAAINyqtVqzb8zXq+2iIgINn/+/Jq/d+zYYfbzefXqFQuAHTdunMFz48aNY/VPYwBYmUzGxsTEaJZduXKFBcDOnz9fs+yHH35g3dzc2GfPnmmW3b17l5VIJAb7zDjO0aNHTZaTZdNff8Zn5e/vz7Zp04ZduHAh++jRI4N1u3btyubKlYt9/fq1zvLWrVuznp6emvfv6NGjLAC2aNGibGpqqma9uXPnsgDYa9euaZY1bNiQzZcvn8GxHjx4wAJgV61apVnWsWNHFgA7ZcoUzbK3b9+yrq6uLMMw7MaNGzXLb9++bfAZ8P2+ZBw7R44c7Js3bzTr/e9//2MBsLt379Ys69u3r8F7z6VDhw4sANbb25tt2rQpO2vWLPbWrVsG640dO5YFwG7fvt3guYzv7Jw5c1gA7Lp16zTPKRQKtnLlyqy7uzublJSk83o8PDzYly9f6uyrTp06bMmSJdmPHz/q7L9KlSpswYIFeb8u4nyoGY589fz9/XHlyhX06tULb9++xZIlS9C2bVv4+flh0qRJYFnWqv23bNkSHz58wJ49e/Du3Tvs2bPHoia44OBgHDp0SOcxbNgwAOkdYwFg0KBBOtsMHjwYALB3716d5SEhIYiIiNBZtmXLFlSvXh3e3t54/fq15hEeHg6VSoUTJ04AALZt2waGYTBu3DiDMmo3m2j3gUpMTMTr169Ro0YN3L9/H4mJiQAALy8vAMCePXuQlpYm+D0xJTw8HKGhoZq/S5UqBQ8PD9y/fx9Aeo3K4cOH0aRJE50O8gUKFNDUAGobP348WJblrFUC0l//wYMH8dtvv8Hb2xt///03+vbti3z58qFVq1aaPkssy2Lbtm344YcfwLKszvsdERGBxMREXLp0SWffnTt31ukTU716dQDQvCZLdevWTfNvLy8vFC5cGNmyZUPLli01ywsXLgwvLy+dY/H9vmRo1aoVvL29bVr+VatWYcGCBQgJCcGOHTswZMgQFC1aFHXq1MGzZ880623btg2lS5c2WrOT8Z3dt28fAgIC0KZNG81zUqkUAwYMQHJyMo4fP66zXfPmzXVqId+8eYMjR46gZcuWePfuneb9iI+PR0REBO7evatTJpK1UDMcIQBy5cqFxYsXY9GiRbh79y4OHjyI6dOnY+zYsciVK5fOBUUoX19fhIeHY8OGDUhJSYFKpUKLFi0E7ydbtmwIDw83+tyjR48gEolQoEABneUBAQHw8vLCo0ePdJZnNKVou3v3Lq5evWq0GQpIbzID0vvlBAYGwsfHh7O8p0+fxrhx4xAVFWXQ1ycxMRGenp6oUaMGmjdvjgkTJuCPP/5AzZo10aRJE7Rt21bQSEF9efPmNVjm7e2Nt2/fal7Lhw8fDN4vAEaXCSGXyzFq1CiMGjUKL168wPHjxzF37lxs3rwZUqkU69atw6tXr5CQkIClS5cadE7OkPF+m3pNGYFHxmuyREZ/M22enp7IkyePQX8hT09PnWPx/b7Ys/wikQh9+/ZF3759ER8fj9OnT2PJkiXYv38/WrdujZMnTwJI/842b96cc1+PHj1CwYIFIRLp1iEULVpU87w2/d9QTEwMWJbFmDFjMGbMGKPHePnyJXLnzi3oNRLnQMESIVoYhkGhQoVQqFAhNGzYEAULFsT69eutCpYAoG3btujevTtiY2NRv359TY2KrfFN0Ghs5JtarcZ3332nqa3SV6hQId7luHfvHurUqYMiRYpg9uzZCAoKgkwmw759+/DHH39oOgAzDIOtW7fi7Nmz2L17Nw4ePIguXbrg999/x9mzZ832uTFFLBYbXW5tLaFQuXLlQuvWrdG8eXMUL14cmzdvxurVqzWv/6effjLZT06/X5Y9XpOpffI5ltDvi70/kxw5cqBRo0Zo1KgRatasiePHj+PRo0eavk22pv8byvhMhwwZYlBrm8HaQJw4DgVLhJiQP39+eHt748WLF1bvq2nTpujZsyfOnj2LTZs22aB0uvLlywe1Wo27d+9q7oSB9E7ECQkJvC4YoaGhSE5ONll7pb3ewYMH8ebNG5O1S7t370Zqaip27dqlU6Nw9OhRo+tXqlQJlSpVwuTJk7Fhwwa0a9cOGzduRLdu3eySodvPzw8uLi46o8kyGFtmLalUilKlSuHu3bt4/fo1fH19kT17dqhUKrPvtxCZmc2c7/dFCFuVv3z58jh+/DhevHiBfPnyITQ0FNevX+fcJl++fLh69SrUarVO7VJGIlFzv6H8+fMDSP+sbfmeEOdAfZbIV+/cuXN4//69wfLz588jPj4ehQsXtvoY7u7uWLx4McaPH48ffvjB6v3pa9CgAQAYjECaPXs2AKBhw4Zm99GyZUtERUXh4MGDBs8lJCRAqVQCSO+rwbKsJlGktoxagoxaBO1ag8TERKxatUpn/bdv3xrULJQpUwYANCkPMkY52TJHkVgsRnh4OHbu3Innz59rlsfExGD//v0G6/NNHXD37l08fvzYYHlCQgKioqLg7e0NX19fiMViNG/eHNu2bTN6Ebc0R1C2bNk0/cHsje/3RYhs2bJptjcnNjZWM1xfm0KhQGRkpE6zdPPmzXHlyhWDUaHA5+9ogwYNEBsbq3Mzo1QqMX/+fLi7u6NGjRqc5fHz80PNmjXx559/Gr3Bysy8T8T2qGaJfBVWrlxpNM/Ozz//jL/++gvr169H06ZNUa5cOchkMty6dQsrV66Ei4uLQXJBS9k6LYG20qVLo2PHjli6dCkSEhJQo0YNnD9/HmvWrEGTJk1Qq1Yts/sYOnQodu3ahe+//x6dOnVCuXLl8P79e1y7dg1bt27Fw4cPkTNnTtSqVQvt27fHvHnzcPfuXdSrVw9qtRonT55ErVq10K9fP9StWxcymQw//PADevbsieTkZCxbtgx+fn46F5I1a9Zg0aJFaNq0KUJDQ/Hu3TssW7YMHh4emgDQ1dUVxYoVw6ZNm1CoUCH4+PigRIkSKFGihFXv2fjx4/HPP/+gatWq6N27N1QqFRYsWIASJUrg8uXLOuvyTR1w5coVtG3bFvXr10f16tXh4+ODZ8+eYc2aNXj+/DnmzJmjCSSnTZuGo0ePIiwsDN27d0exYsXw5s0bXLp0CYcPH8abN28Ev6Zy5cph06ZNGDRoECpUqAB3d3e7BOcA/++L0PID6Zm5IyIiIBaL0bp1a6PrPn36FBUrVkTt2rVRp04dBAQE4OXLl/j7779x5coVDBw4UHP8oUOHYuvWrfjxxx/RpUsXlCtXDm/evMGuXbuwZMkSlC5dGj169MCff/6JTp06ITo6GsHBwdi6dStOnz6NOXPmIHv27GbLv3DhQlSrVg0lS5ZE9+7dkT9/fsTFxSEqKgpPnz7FlStXBL0fxIk4YggeIZklYwi/qceTJ0/Yq1evskOHDmW/+eYb1sfHh5VIJGyuXLnYH3/8kb106ZLJffNNHcBFSOqA4sWLc66TlpbGTpgwgQ0JCWGlUikbFBTEjhw5UmcYs7ljvnv3jh05ciRboEABViaTsTlz5mSrVKnCzpo1i1UoFJr1lEolO3PmTLZIkSKsTCZjfX192fr167PR0dGadXbt2sWWKlWKdXFxYYODg9np06ezK1euZAGwDx48YFmWZS9dusS2adOGzZs3LyuXy1k/Pz/2+++/Zy9evKhTrjNnzrDlypVjZTKZzhB2U6kD+vbta/Da8uXLp0m1kCEyMpItW7YsK5PJ2NDQUHb58uXs4MGDWRcXF531+KYOiIuLY6dNm8bWqFGDzZUrFyuRSFhvb2+2du3a7NatW42u37dvXzYoKIiVSqVsQEAAW6dOHXbp0qWadTJSB2zZskVnW2PpAJKTk9m2bduyXl5eLABNGgFTqQOyZctmUCZT3zVj3xs+35eMY8+cOdNgn9qfJcumf6/69+/P+vr6sgzDcKYRSEpKYufOnctGRESwefLkYaVSKZs9e3a2cuXK7LJly3TSWLAsy8bHx7P9+vVjc+fOzcpkMjZPnjxsx44ddVI3xMXFsZ07d2Zz5szJymQytmTJkjrvmbnXw7Ise+/ePbZDhw5sQEAAK5VK2dy5c7Pff/+90c+fZB0My2Zyj0dCCHFiTZo0wY0bN3D37l1HF4UQ4iSozxIh5Kv14cMHnb/v3r2Lffv2mc2nRAj5ulDNEiHkq5UrVy506tQJ+fPnx6NHj7B48WKkpqbi33//RcGCBR1dPEKIk6AO3oSQr1a9evXw999/IzY2FnK5HJUrV8aUKVMoUCKE6KCaJUIIIYQQDtRniRBCCCGEAwVLhBBCCCEcqM+SDajVajx//hzZs2fP1OkGCCGEEGI5lmXx7t07BAYGGkyirI2CJRt4/vw5goKCHF0MQgghhFjgyZMnyJMnj8nnKViygYw0+E+ePIGHh4eDS0MIIYQQPpKSkhAUFGR2OhsKlmwgo+nNw8ODgiVCCCEkizHXhYY6eBNCCCGEcKBgiRBCCCGEAwVLhBBCCCEcslSwdOLECfzwww8IDAwEwzDYuXOn2W2OHTuGb775BnK5HAUKFMDq1asN1lm4cCGCg4Ph4uKCsLAwnD9/3vaFJ4QQQkiWlKWCpffv36N06dJYuHAhr/UfPHiAhg0bolatWrh8+TIGDhyIbt264eDBg5p1Nm3ahEGDBmHcuHG4dOkSSpcujYiICLx8+dJeL4MQQgghWUiWnRuOYRjs2LEDTZo0MbnO8OHDsXfvXly/fl2zrHXr1khISMCBAwcAAGFhYahQoQIWLFgAID3BZFBQEPr3748RI0bwKktSUhI8PT2RmJhIo+EIIYSQLILv9TtL1SwJFRUVhfDwcJ1lERERiIqKAgAoFApER0frrCMSiRAeHq5Zx5jU1FQkJSXpPAghhBDyZfqig6XY2Fj4+/vrLPP390dSUhI+fPiA169fQ6VSGV0nNjbW5H6nTp0KT09PzYOydxNCCCFfri86WLKXkSNHIjExUfN48uSJo4tECCGEEDv5ojN4BwQEIC4uTmdZXFwcPDw84OrqCrFYDLFYbHSdgIAAk/uVy+WQy+V2KTMhhBBCnMsXXbNUuXJlREZG6iw7dOgQKleuDACQyWQoV66czjpqtRqRkZGadQghhBDydctSwVJycjIuX76My5cvA0hPDXD58mU8fvwYQHrzWIcOHTTr9+rVC/fv38ewYcNw+/ZtLFq0CJs3b8Yvv/yiWWfQoEFYtmwZ1qxZg1u3bqF37954//49OnfunKmvjRBCCCHOKUs1w128eBG1atXS/D1o0CAAQMeOHbF69Wq8ePFCEzgBQEhICPbu3YtffvkFc+fORZ48ebB8+XJERERo1mnVqhVevXqFsWPHIjY2FmXKlMGBAwcMOn0T8rX6mKaCi1Ts6GIQQojDZNk8S86E8iyRL9Xeqy/Qd8MljPm+GLpWC3F0cQghxKYozxIhxGo/b/wXADBpz00Hl4QQQhyHgiVCCCGEEA4ULBFCCCGEcKBgiRBilZdJH5GmUju6GFlCQooCU/bdwp/H7+F9qtLRxSHEqWy+8ARVpx3B3bh3ji6KAQqWCCEWu/4sERWnRKLJwtOOLkqWMGrndSw9cR9T999G97UXHV0cQpzKsG1X8SzhA4ZuveroohigYOkrxrIslhy/h6N3Xjq6KCSL2vHvMwDAjec0mTQf0Q/fav595l48ACBVqQINSib6nid8wKXHb82v+AVSqtVIVaocXQwdFCx9xU7FvMa0/bfRedUFRxeFOKHIW3FQqukibk83nyeh8OgD6Pf3v44uSqYase0qJuy+4ehi8JL4IQ0xLzO/WajKtCNotugMbjxPzNTj3n+VjD+P30OKwrbNxB8UKjRacAqz/7ljdt3rz9J/F9P237ZpGaxBwdJX7HnCB0cXwW7UahZHb7/E6+RUs+s+in+PEduu4v6rZF773n3lOabsuwWFUng/HYVSjXH/u44jt+PMr+xgXddQM5GtMYzu3w3mnQSQns/KUS4+fINfd1xDYkqaXfb/8HX67+vB6/cAgGcJH7DxwhOsOv3Q6WoPjKk0JRLhs09wBi1JH9PwMS39tbAsa9M+fJefJNhsX3zU/v04pu6/jVkH/7PpfrdEP8HVp4mYdyRGs+xO7Dtc4Xh9S47fs2kZrEHBErG7+ORU9P/7X5yJeZ1px9x44Qk6r76Aun+cMLvuTyvOYeOFJ2iz7Cyvfff/+18sPXEfhUbvx9bop4LK9dfZR1gT9QhdVmf9QCQ5VYl91/hf5G8+T0L0I91mhYVHY1B12hGL72ITUhQ4cD3WosCVy7n78XbpZMqYX8Xu7sS+Q4vFZ3DmXvrvscWSKGw49xhT9t2yy/HaLU//fbVeGoXrzxKxQOtiaS21msWoHdfw9/nHFgUoLMua7GivVKlx8EYsPnwKgk78Z/z8lZyqRKnx/6DsxEMAgH5//4vSE/7Bm/cKweUxV9Yjt+My7SY3+tEbm+4vTaVbS82yLCLmnEDjhafx1sbvlT1QsPQV+aBQ4XTMa5MnlQev3+OZFT/E2MSPRu+CJuy+id1XnqPt8nNQqVmcufca7z7a5y42w6GbsQDA64T15E36a45LMl8LpW/IliuC1n+h9/6+fPcRy0/eR0IKv5MFy7KYvPem4CDNHkqMO4gXiR95r99g3kk0X3wG8Vq1fTMP3sGzhA/4brb5oNaYln9Gode6aMw/ctei7Y158iYFrZaexXc8Au2sqMvqC7j46C3aLjunszyj5sdai47FYNmJ+5q/M84pcUmp+H7+Kfx9/rGpTQU7/t8rrD/3GCO3X0PJ8Qfxy6bLgrYPGbkPxccdxLn78QbPLT/1AD3/itb8bao2+E5selCdEVTtvfoCKQoVtl/6/BtNUSgxP/IuYgX8XvQdvBGHLqsvosq0Ixbvw1m94tEC4GgULGUhT96koN3ysygyZj8O3RTejNP/70tot/wcpu4zbAdO/JCGWrOOoaoVP8RKU9NHRWWcPDI8fZui+fdve2+i7bJz+HFJFADgr6iHqDrtCB5qnaifJ3zA3MN3eTWhCfExTYV6c05g3P+u23S/GU7efYWCo/bh2KcO81ujn+LAde6alw4rzuO3vbd4n+RPx8Rj2ckHRoO0ZwkfUH3GEZ0LlVDJqUok23lIu7Gg1JIg/VnCB/wXl950uvvKc6vLleFhPHfQ8L/Lz1BlaiSuPzPfl4RlWbxM+nyBfPfR9u/txvOPUXXaEd79amz9u9L25r0CMw7cweR9t/BBYf8mtsQPn2+6PqapNQMO3rxXCKptbLXUsFb5wPVYnb8vPLS8s3WZiYfw+6H/UGlqpOBtR+24jsSUNJw1EtAJ8SzhA6pNt+788DWjYCkLab74DE7HxONjmtqiYceHb6VfxNdGPTR47kWi8ItV9KO3ePXO8MTL1Qa96nT6sW9/CqjG/O8GniV8wHitzp5tl53FH4f/Q5/1lwSXicueqy9wO/Yd1kQ9sul+M7RfcR5pKhadVl1AbOJHDNlyBb3Wcb+GjPfh6J1XvI7xlqMGauaB23jy5gMmW9ickqZSo8S4gygx7qBN+lywLItz9+Pt1hdmeiZ0/uyzPhpJerWgP2+8jOeJH9F3g/nv5y+bLqPilEgcvJHeVPjODoHoiO3X8CzhA4Zvu6az/FH8e3RfexFLT9yzuJkjRaHEmXuvoeT5fdDugxTzkl8fwM/rv+Pdb5DL07cp+GbSIYTPPo6EFAXO3Y8Hy7I4dfc16s89iatPE6w+hlDWNhN3WXMB/1o5Mm7Ggdt4+tby88PXjoKlLOSlkcDE7DZJH7Hz32cGP9YD12Nx75X5aneWZbHn6nM80rrbvhv3DpP33kTzxWdQYfJhwWXS3k8Gldaoq4fx6TVR5x/Yts08M4fhat/xPrRR84Y51o5cS9AKavpyBKozD95GGyN34vp2XXmOVkvPou6c41aVyxSl2v6JMPddi8Xcw8ab+JQq8+/3zsvpNV4LjsQgLsnyJhg+9AOa3usu4dDNOEzZdxu1fj8maF9H77zE8f9eodjYg2i77BwWHBXez+iHBaeg5vmdfJ+qRPjsE6j9+3HegZkpR26n3xQ+fpOCun+cQKulZ7H76gv8tOIcbr1IQoeV563avyNEP3qLK08tGxV35UkCTt59xev7SkyTOLoAxL4azDuJ18kKnaYFpZpFr3XRHFt9tvfaC/TbkD6s+eG0hgBgs74c2vs5efc1asw8il19q+msc/lJAh7Fv0fjMrkNtmdZFoz+8CIOG87Zrq+EEDVnHcODqQ0MyqrdPJnhTMxrpChUCC/mb/dycb1//3A08y48anyEyvVnifgv7h2afZMHwOdmjLikVIPaGUvzCpkq8+tkBa/1LNu3bZqtUgQ2S118+AYv36WiQclcmmWHb8bBTSZGlQI5Dda/8jQRFx++QflgHwDpzfYZEgTU7t17lWyQTmTj+ScYGF5IZ9nBG7HwdJWiUv4cmmUn9TpB/3NTtynLlHitz0+hUkMits19fMYN5sEbn8vBtyk0s0ILS76rfPfDsiwaG0kYm5CiwO4rz9GwVCB8sslscqwvHdUsZWHGOiVqU6lZzUXk6G3LEk9etKKdXqhH8SlYfeahzrImC0/j542XDWqFbr1IQoXJkVh/zromNVv2deFSY+YxjN+lm1cmfLZujUvMy2S0XX4O3dZeNNq8qS/eiov4rivPETJyH0Zss12m3O/nn8KgzVdw2sioR+3jsGDRZtlZtFt+zmA9LkO3XMF3f5zQGqL9+bnkVCVUahZbLj7B2qiHCBm5DzMO8G+muxv3DhUmRxptonaEXVeeo8WSKPRZfwn3PjVNvXz3Ed3WXkTb5efw9/nHePteYXAD0OJTX0BLnH/4BqdjXvOqCX36NgU9/4pG66Vn8ceh9CHmH9NUGKb3fTLXDA2kf3Y1Zx3V/G1t3xxbOP7fK87uBLby256bqD7jqE5NtCXOxLxG+d8O6/SzSlWqUG/OSaPrl5l4CGP+dwPfTDqEwwL7v/b6KxqNFpzWaQ34GlCwlAWciXmtc5eYIaNTIsuy6LTqvE7TSZpKje/+4N/8Md/K4bx8q9vN7sdEjcOCIzGIuheveR+Gbb2K18mpGLXjutnmtQ4rzxutyYi6F4/+JpIBPo5Pseqkrd8H7PGb9EBw+akHmmUf0/SbTT7X9nH1Tcqw4tQDsCyL4/+9EtTn7P6rZAz49Lo3XnjCezu+/jMy5P7gjc8n5FfvUnH2/htNBmu+tkQ/RczLZETeMh74b7n4BEO3XsXY/6UHpYuO8c/R8uuOa3idnKrZ1hYsrT07dfe15vMBPudD23Pl82CBkduvoemi0/h1xzWD7d+8VyDqXrxF/aPaLT+nGdWlL+ZlMkbtuIbnCR90ugTMjbyLhBSFJogV4mNaej857dNHl9UXNd0Gzj94g3H/uy5o0MGtF9wd3VVqFoduxhmU9+17RXoiVpUaHU001YXPPm5wIyO0n5V2f8Dlpx7g6dsPgm/69AdEtF1+DvHvFei1LhqHb8Yh8UMaTt19jTs80l900+r/qn0eeWuiNvLAjVhce5Zo0PcrRaFEg7kned2kGLueOTsKlpzcpcdv0Xb5OVSfcdTkOk/ffsCxO6+w99oLTQfLDece4z6PPkkZ9JPipSiUgr7Qe7Xy7SSnKtF22VlM/dSRUMglY26k8f4hR26/RJtlZzXvwzWtkUjNFp3RDMm9/yoZaSq1zjFP/PfKYFj06+RUzrxK3848itZLz1qcPXf6AfNZavXd1eoQyyd/0aJj97Dy9EN0XHkelafyH8X49K1l6SGWHL+H4BF7LdpW+y60k5UZ46fsu4XbsYbTq1x8xL8W9MHr9zqdkbVHOh29za+zPZAeEA3besVojiLtu/xrzxI1I7VMWfOpVvXWC8PX9u/jt5i456bOsoy+ffpqzDzKO2eYMfpBfIamC09j/bnH6LUuGg/0zi2W9pc7eN14M92S4/fwPOEDWv4ZhTVRjzD3sPEEicZagoylJtAfmdd97UWDQLP85MPouuYiVp5+AFNiXiZjgV6aCv3aNG3vPqYZ5EUyViMTdS8ezRad5l3LwzUJc7e1Fz/dIPLaFYD0mkwAOueRx3rn/+Un76Pbms+/Xe1muHcf01Bs7EHcfJHE6yaF63qmT61mEfPyncOnBKJgycn9+zjB7DratTEfFCpM3X/L4GIr9GtWddoRVJ9xlPeIFu3Oq8tP3seZe/H488R9/O8y9wXCVp68TcHeqy9Q+/fj6LTqPI7pjS7TPz8ZS5+QQTufyo1nls15prAyM/GcT52KWZbVOUnoj1KbpHcBtafMmHpA/4QY/egNgkfs1Ulo+izhg9HmBb7n0mN3XqLWrGOa9BX6TF0sLzx8Y5Co8mF8CjZffIqln4Zja39eJ+7qNkeay0Y8bpfpWq1LPM4DGYSkJxByAcqoqbr6NBGDBeYXM8VUTfLsQ//p5BMyFRjydcRIN4Ttl3TPTRlBzOpPI3ZNUajUePtegcl7b+JO7DvO713pCf/wyot08u5rXHqcoKnlsTYwuPIkAWsENCkP4DHdzm97b2lGVOtbasd0BJP33UL47BOYfci2GcWFog7eTs7ckNOoe/Fwl3/+GMt8yiKr76rAkRQZVbCneGTd1q8Sfq6VeE2/D5I9ZdyZn44x37zD1cyl3Q/k9L3XaFQmEC5SsaCy2KLzo0KpRqHR+9PL1C0M5YN9MGizbS5S2jaef4zWFfPafL9CKVVqtPwzCjnc5VjWoTwAoPni9ICmrZH+TfrXk22XzCfqfBT/XlOzlfGbMFZLpe/p2xSD4IplWZ2cYmkqNQqOSv+8GpbKBQ8Xqdn96jNVm2uvu+qwKYZ5f4QmWrWGJYlggfRmcnvlA3tuJnHk3+ef4O/z6c3Xy06aroUCDG/StJlKqaFWs2i11Hzfs7P34/Ff3DvULORn9PmTdzNvxoQkK/tccVnxqevC/CMxGFy3sN2OYw4FS05uupn23zbLzkIssu2ohCZGRk9wmbj7Bip8GoGjj0/NmFDGLhybLjzB+YemUw38tpdfDYx+zc3/Lj/HxzQV/mxf3uQ2+6+90GkWtJWTdz/XjrVdfg5tw/gHNKtPP0CnqiEGy58lfDCoZRyx/ZpTBEt7r73Q1KCciXmNb/J52/wYv+3VbS5LSFGY7ASr7ZGRmo3niR8xUSs/mHYTyt6rL9DGgvd06v5bKBtk+Lrt8f0C+KcjsdfAp+RUyy6y385Mb8YZ3bCoLYtjNe0m1JtGmlO11Z9rfFTxw/j3ZhNgPopP0cq15/gJiS3pH2fL/oGZgYKlL4CtRyUInbgxs5uSV5wyvJszN/2HfrOcqRxOqUZq8rQ7JxvrK9DbxskzM+i/r0JSH4zffRNP337APzfjsKVXZXi6SlFkzAEAQCF/d6Pb7DTTp4avCbtvwt/DRfB2P2+8rPl32+Xn8H2pXKZXRnpHU75G7biGy08S4OWmW9tj7cirFK1OwhN26wbkloy0NPVbtmXOMXv9XBUW5Efi+xkeuhmHRcdiEFE8AKG+n7+/OzOpmZ+v+nM/B976zXz6TNVgrTLTDAjAoqTE9qLWGnUtxF9nP3dqzwo5oChYIlZ78vYDKhpWYtiNfu2AJbiq8F+Z+OH323AJexw4O7w5+k1/GSPvqk0/grrFAjTLM6YI0WfLzL591l9C/RIB5lfkYMv3er2JQJPP0HYAJod2a+cvitVLOmmrZqItF58KmoPPEfZefYE9V4UHhxnzMvIx48AdzDhwB3+2L6dZdt3CPoWOtOHcY3SsEmzyee0gIjNxpS8wNugASG82bjDvpNXT+JyKeYVigR5W7cPeqIM34a372otGE/TdepFk9/nEMpOp/CrOHCgBQKyJ9AFpKlZntOLXZNSOa9hvg9c+UKvWK7PtslEusA8KFUZsu2r11BvGjNt1w6q504TYaMOJeB1h4p6bCP11n6OLYYBrfkrtGjNtcyPvGg2UrgnsI+vggW68UM0S4e3QzTgcvmV8aOscE1NCZDVpJi4kf5oZyeQMrLlYGcvXY639JoaFZ6b15x6brFUSwpImJkvcfZms0+xrS0tP3Lc4r5Yt5gokzs3YiEFLDd16Bbdj32Hwd4XQv05BnIl5zTlyV81aP3+evVHNEhEkK9wBWOOb34yPJpwqcNi80ElEHc1RU8EQXUJyowllyWTZGSzpk0KyPq4JmNUsa7LpLmOC8N8P/QeVmjU6mlXb9AO3NSN/nRXVLBGi5UsPBolw9J1wLrEWphsgwpWddAi/6M0JmKHZojO89uGMTY6WoJolQgjhwCcPE8k8pjobE/v4w0T29K8NBUuEOKlIG/YhIJYzNXqQEJK5HDmQiIIlQpyUsTmuCCHka5XAY4Jxe6FgiRBCCCGEAwVLTuwVz6kICCHEHGPZ6Qkh/FCw5MQqTD7s6CIQQr4QO2w0nQ0hXyMKlgghhBBCOFCwRAghhBDCIcsFSwsXLkRwcDBcXFwQFhaG8+fPm1y3Zs2aYBjG4NGwYUPNOp06dTJ4vl69epnxUgghhBCSBWSpDN6bNm3CoEGDsGTJEoSFhWHOnDmIiIjAnTt34OfnZ7D+9u3boVB8HmoYHx+P0qVL48cff9RZr169eli1apXmb7lcbr8XQQghhJAsJUvVLM2ePRvdu3dH586dUaxYMSxZsgRubm5YuXKl0fV9fHwQEBCgeRw6dAhubm4GwZJcLtdZz9vbOzNeDiGEEEKygCwTLCkUCkRHRyM8PFyzTCQSITw8HFFRUbz2sWLFCrRu3RrZsmXTWX7s2DH4+fmhcOHC6N27N+Lj4zn3k5qaiqSkJJ0HIYQQQr5MWSZYev36NVQqFfz9/XWW+/v7IzY21uz258+fx/Xr19GtWzed5fXq1cPatWsRGRmJ6dOn4/jx46hfvz5UKpXJfU2dOhWenp6aR1BQkGUvihBCCCFOL0v1WbLGihUrULJkSVSsWFFneevWrTX/LlmyJEqVKoXQ0FAcO3YMderUMbqvkSNHYtCgQZq/k5KSKGAihBBC7IhlHXfsLFOzlDNnTojFYsTFxeksj4uLQ0BAAOe279+/x8aNG9G1a1ezx8mfPz9y5syJmJgYk+vI5XJ4eHjoPAghhBDyZcoywZJMJkO5cuUQGRmpWaZWqxEZGYnKlStzbrtlyxakpqbip59+Mnucp0+fIj4+Hrly5bK6zIQQQgjJ+rJMsAQAgwYNwrJly7BmzRrcunULvXv3xvv379G5c2cAQIcOHTBy5EiD7VasWIEmTZogR44cOsuTk5MxdOhQnD17Fg8fPkRkZCQaN26MAgUKICIiIlNeEyGEEEKcW5bqs9SqVSu8evUKY8eORWxsLMqUKYMDBw5oOn0/fvwYIpFu/Hfnzh2cOnUK//zzj8H+xGIxrl69ijVr1iAhIQGBgYGoW7cuJk2aRLmWCCGEEAIAYFjWkV2mvgxJSUnw9PREYmKiTfsvBY/Ya7N9EUIIIVnZyWG1EOTjZtN98r1+Z6lmOEIIIYSQzEbBEiGEEEIIBwqWCCGEEEI4ULBECCGEEMKBgiVCCCGEEA4ULBFCCCGEcKBgiRBCCCGEAwVLhBBCCCEcKFgihBBCCOFAwRIhhBBCCAcKlgghhBBCOFCwRAghhBDCgYIlQgghhBAOFCwRQgghhHCgYIkQQgghhAMFS4QQQgghHChYIoQQQgjhQMESIYQQQggHCpYIIYQQQjhQsEQIIYQQwoGCJUIIIYQQDhQsEUIIIYRwoGCJEEIIIYQDBUuEEEIIIRwoWCKEEEII4UDBEiGEEEIIBwqWCCGEEEI4ULBECCGEEMKBgiVCCCGEOD2WddyxKVgihBBCCOFAwRIhhBBCCAcKlgghhBBCOFCwRAghhBDCIcsFSwsXLkRwcDBcXFwQFhaG8+fPm1x39erVYBhG5+Hi4qKzDsuyGDt2LHLlygVXV1eEh4fj7t279n4ZhBBCCMkislSwtGnTJgwaNAjjxo3DpUuXULp0aURERODly5cmt/Hw8MCLFy80j0ePHuk8P2PGDMybNw9LlizBuXPnkC1bNkRERODjx4/2fjmEEEIIyQKyVLA0e/ZsdO/eHZ07d0axYsWwZMkSuLm5YeXKlSa3YRgGAQEBmoe/v7/mOZZlMWfOHIwePRqNGzdGqVKlsHbtWjx//hw7d+7MhFdECCGEEGeXZYIlhUKB6OhohIeHa5aJRCKEh4cjKirK5HbJycnIly8fgoKC0LhxY9y4cUPz3IMHDxAbG6uzT09PT4SFhXHukxBCCCFfjywTLL1+/RoqlUqnZggA/P39ERsba3SbwoULY+XKlfjf//6HdevWQa1Wo0qVKnj69CkAaLYTsk8ASE1NRVJSks6DEEIIIfbDMI47dpYJlixRuXJldOjQAWXKlEGNGjWwfft2+Pr64s8//7Rqv1OnToWnp6fmERQUZKMSE0IIIcTZZJlgKWfOnBCLxYiLi9NZHhcXh4CAAF77kEqlKFu2LGJiYgBAs53QfY4cORKJiYmax5MnT4S8FEIIIYQIRNOd8CCTyVCuXDlERkZqlqnVakRGRqJy5cq89qFSqXDt2jXkypULABASEoKAgACdfSYlJeHcuXOc+5TL5fDw8NB5EEIIIeTLJHF0AYQYNGgQOnbsiPLly6NixYqYM2cO3r9/j86dOwMAOnTogNy5c2Pq1KkAgIkTJ6JSpUooUKAAEhISMHPmTDx69AjdunUDkD5SbuDAgfjtt99QsGBBhISEYMyYMQgMDESTJk0c9TIJIYQQ4kSyVLDUqlUrvHr1CmPHjkVsbCzKlCmDAwcOaDpoP378GCLR58qyt2/fonv37oiNjYW3tzfKlSuHM2fOoFixYpp1hg0bhvfv36NHjx5ISEhAtWrVcODAAYPklYQQQgj5OjEs68hWwC9DUlISPD09kZiYaNMmueARe222L0IIISQrOzG0FvLmcLPpPvlev7NMnyVCCCGEEEegYIkQQgghhAMFS4QQkolEUDu6CIQQgShYIoSQTFKMeYhb8k7oI/6fo4tCCBGAgiVCCMkkm2STIGeUGCbd5OiiEAf7SXwIR2W/IA/z0tFFITxQsEQIIbywKM3EwAWpFu8hO/PBhuUhWdlv0lUIEcVhjGSdo4tCeKBgiVgtEK/BUD8M8oVrKz6C/8nHYr1siqOLQr4gEqgcXYQsg4XjMh1RsESs0kJ8HGdcBmC6ZJmji0KIXbUWHwEAlBPddXBJCMnauov3YJhko6OLIQgFS05ODgVqiK5ADoWji2LUQMk2AEBLyXEHl4QQ+2IceFdLvlxf47dqlHQD+kh2IS8TZ35lJ0HBkpP7XboEa2TTMVm60tFFITZST3QexZkHji4GEYhxdAGysG+Y/7BXNhIVmNuOLgpxIi5OWglgDAVLTu578VkAQAvxCQeXhNhCaSYGS2RzsFc+ytFFIQLZo2apquga/pJOQZDeHXZuvEJd0QV8KfUO2+XjUVz0CFvkEx1dFKfDUhieJVCwRL4IHkiGB5LNrMV+GqbruAtQAea5w45tK674iJxIdHQxMp32JW2D9Dce3zfz1sumorr4OuZKF+osP+3yM5bK/kAD0Tmrj0HS+eItuon3wtMGn5ttfb3BUlYKFClYIlmeBEpcdemBqy49IIHS5Hr9xTtwSj4QgyVbMrF0X55oeW9cdOkNXyQ4uiiZSrtmqYr4JvpLdtps39+IYowuDxPdstkxvnbrZVMwWroef0gXObooJAuiYIlkeV54r/m3B1JMrjdYuhUAbHqR+5r0Fe/EWulUuDHpeYa++epGhenWSLqDcibZGgM1/PHGLvsuJHoGAKgtvmyX/Vvqy2hoFSJrvmIKlrI4TySjj/h/CMRrhxyfZbmrUX2QBDHlEfkiDJVuxrfia5l2PG8kYZ9sJLqK92baMbnYusGgCPM404/pPIxfMOdIF+GcSz9EiM5ncnkcJys1RdlaVgqbKFjK4mZK/8Qw6SZslY93dFEMhDLPcMmlF3bKxji6KE7DlbE8+/PXpo9kF4qJHmGMdL2jiwLA9h28m3+lgzZy4xVOywegp3i3wXONxWcApH/25MuUVVNwULCUxVUXpd/pBzL2qbq2RhPxaQBASdHDTDtmxg/RBalYJZ2OtuLITDs2Hz3Fe3it54qPmC5Zipqiy/YtkBOTI81hx86MjPTdJft4lCNrXli4DJNuQm4mHiOlfzu6KE7h665ZEvbaY146rnM+BUvEZvIwrzBC8rfd+hyYYuxy0kl8ELXEVzBFuiJTy2KOP8+gtpdkN1pJjmG1bIadS2Q9N3w0GPqelbUTH8YVeQ+UYu7pLNcPXDIjjPkSgyUxj0C0tOh+JpSEOII1oWFckuNq5ilYIjbzt/Q39JLsxlLZbJvut4boiuCLsSfz3vxKDsD3RBGIeLuWwxYyLuOn5ANwUv4LCjFPHFoeW5ksXQkPJgVz9Ibzf733/8SevBhnS2XgvGhuOGIREdRwZSzLgCqzUROH9lc3SPQKgG3vCsOYW1gjm46T8l8EbcfnwuaKj9gmG4e+4p0Wlc0Soi9owuGlsj/wh3QhfD6d7GuKLqO7eA8aiU47uGT2YUktDwP1V5digQhTidJDZAkULGVhLcSWzcf2DfMf/nPpiKF2nsiQ38WFRXaO4f5Ch6d/DpLMH7uN+CjKie5iqHQz7/3nxivUEv3La//GfGm1E03FnwOjgswzjJJuwDzZQo4t+Muce0gW3zD/Gf0O6n9/LQmWFkvn4oJLH1QXXTW7blWR4UhDR35fwphbWCadhdx45cBSENtyfLOu9u9IaJ8lxoG/CAqWsrBQC7NBj5X+BQDoa4MRJ1xfdj4XlymS5bjm0g2VRDct3oexMoh4bOdhQVPdaZefsUo2E7Xs3PGa632tK7qAXyRb4AwnPm18mxM8kIxxkjUowTi+X8oPoihsl4/HXtlIC7Y2f+KuJ74AAOgmNt+Ze71sqpEjcH/GRZjHGC75Gx6wfbPzJvkkfCe+hNmyxTbftzWKMo9wUvbzF1uDaS8iqPE/2Rgsks5xdFE0slLndgqWiEO1lRwFAPws3m7T/fIJsn4QRVm8/zCR9ROCVhFdN/kcV/mXyv7Az5Iddg/YhON34hsrXYfOkoPYIx/9aSu1w3Jx/SBO/w7kFZmvPTH8TDIjWOU+xgH5CPSW7MYoifD0CgzUaC0+ggLMU871bN1/LmO+S0vNlS5AkOiVzWowvxalmXsoLbqPBmLH5rDKqoMWLA6WFAoF7ty5A6XS9PQShFjPsh8Wn5qlIOalRftOx73/uqIL+EO6EG74aHKdDbIpVhwf8GMSrNreUQrrJWPcJRuNk/KfOaeqsReu8C6bXk4sPid5rj5p5oISa5SyoJ9gC/EJTJMux2H5MKuObavP7TvRRV7rOTKlRFbmjEGK85XINMHBUkpKCrp27Qo3NzcUL14cjx+nn/j69++PadOm2byAxDK+eItQ5pmji6EhhwLZkYIRkr9RlHlkt+NknBD4nBhkjP1qM5bK/kBT8Wn0lOgm3hMxxsuVHSmoyNzS5PfhUz3tbCcaS8tTUvQQgcwbFNT7vjq6il5oMDpSsh5X5N2Rh0mvpZJqBREsGKuDkqLMIyyV/o6CRoKuoqLHyMfECtpfaa3UCCKo4c7Rd9CUn8SHEOPSAbVFlwAAxZiHGC35y6LJapfZYBRtQeYpfpFssei1EMJFcLA0cuRIXLlyBceOHYOLi4tmeXh4ODZt2mTTwhHLXXDpi0j5UATiNcozt5HNxvNYFWEeY5NsIvKJTNfOaF/qmotPYozkL/SS7MZ+Of/+IXwul9oXaTmThnqi8/AUPBxX2KWe710a35FQ/5ONxmb5JLRwUFbnQswTNBKdgfb7wEAtKDmjo4Mby/D/3PVfXWXRTZ33p6dkL7IzH/CLZAtckIpL8p5Wly7jmLnxCvvlI1FXHI2NsklG1z0uH2TxaMvdslG47tINfnhrWAYTAT4A/CZdBQBYIJ0PANgn/xXdJPsxXrrGonLwkZsxPbXTIfkw/CzZgV8taJb80jnL79M5SiGc4GBp586dWLBgAapVqwaG+fyyixcvjnv37nFsSRxhgnQNtsonYqtsvE33u1Y2TVC/HQmUKM6RyduHSbJBqYARkr+xRDYHzcWnBG3n6Crq/KL0WgEh/ahsefJbLZuOebIFqPypoz0DNQ7IRuAf2XDeARPf8phayx6fQVPRSSyV/g5XjuZQbtrBo275QkRx6CA+ZLBFc/EpVBDdQXbm8w2Kpa8s45inXX7WLMvBvDO5Pp+Ej5/3/VlxUXptb7j4krACmlCUx7x3lpIwX29Sy+9EF+1aM5/ZnCWA40NwsPTq1Sv4+fkZLH///r1O8EScw3fiaABAUZFtEwbyaaLQvrjIkcb5sygsMt6fQ+gF1NrOo7aXNX4TGdPllPnUNOOFZBQWPUVB0TP4wPTF2dn9IVuMuuJok6PRzH2/Lsl7ohjz0OS6E0zUoOj3Vcsa3wLjrzEPR02OtcRQYZxkDe/+SvbQTnwY7cX/IIR5gSGSTfBy0u97CeY+lslmC6qZ1+YsgYmjb0wtJThYKl++PPbu/TwLeEaAtHz5clSuXNl2JSOZRgQ15LAsuSVfo6QbUEwk/I7IO5Oy25Zj/suU45gj5ETig3c4IfsZP4u32ez4w6UbPzW/CcdV8maiE/hdukhQZ2BbntxNZXTXPoKx34APk4zfpYsN1hWqpIU1HUKPKeQy5AwXrRbiE+gsOWiT/kra+L5v2fABk6UrMUm6Gkflg9FP8j9Mly7T2o/zJJEtZMcBAo7iLAEcH4KDpSlTpuDXX39F7969oVQqMXfuXNStWxerVq3C5MmT7VFGYmf7ZSNwQ96Fc+SWJaz9GdQU/Yuukv1m17PkByfVu2gHMIZ9NbjwPaI9Twa9JLuRV/QKv0htFywBwGHZUIu243qts2VL0Fx8irNPlnXvFPeFn8/ncMelEzw4OiZz9d3RV0f0r87fQprHdI4pMKDhep0SKM0Gq7YKoPx4/p5yMY6d1kf/PAAAZUUxAIDhkr9xSd4LuQSmTmghPo79shGajv7axFDB10i/MHNy4xVGS9cJ3s4ZWfMdy1LTnVSrVg1XrlyBUqlEyZIl8c8//8DPzw9RUVEoV66cPcpITLDVZbiw6CkkjBplPp0kvhdFYYdsLAJhv+p3PoZK+GfW5mKsv0o78WGdv+0V1Njzp20sN1EOJFp9NxwqemFRll0+r9UbyTav0XDFRxyVDcJUyTKT65h6DfplqcmRaVtIc1RLiW52fb7B0mzpIqtGsWa8zgDEo57ovOa7IIIaUfJ+OCMfwPn9sNUAAx8m2erv4RrpNDQQWdas7ivw5kebB96jk/gAekt2w5tJRl/JTkHbz5L+iaKixxgn0W2i/VZ0BVfk3XHBpS++4ajJLsvcxXDJ33DB59QVa2XTNNMKAUA90XlMkKwSNHDHnuciKZRoKjppdIAAF64y/Sg+hrnSBUYDWkcQFCylpaWhS5cuYBgGy5Ytw/nz53Hz5k2sW7cOJUuWtFcZCU+VRTes3kd10VUskM1HWVEMJn0a6WIP4yWrbbYvcxffXpI9Bsv07/r4nEgGSrbyPubn/VoWhFmyXQXmNqJdemOZ9HfOdUxlS9emffRgnkPSZVYnlrTsdN5IHIUQURzafEpwars988WavWhpd/bm0kx8Chtlv2n+tjSwPCkfiCWyOWj5aUqkHEiEL5MEPyYBnhzZvsuI7qGkjTKrS3l8H7i+5TXEV7FINs+iY/sySZyd+puJTnw6vuH768KkYbx0rclt3fCRVyDoilSMkfyFw7IhKMw8xlrZdLgz6WVqJ4k0ud0O+Tj0luxGX8n/NMtCRS901lkim4OOkkMYpHVOcqS+kp34Q7YY+yzsT2XMTOlSNBafQTfxPrQRR9olS70QgoIlqVSKbdtsW+VPLKffbPa3jLsZNC8Th5GS9fDl6Jz9l+xzrqx8TJxV5eO6RHWS/MNja3MBQ/r+y4u4+xtxDTU2xxcJyP9pWpmBEttmGTdGxhi7i9LuKG+6b9lg6RYAQLj4X6PPy5CGLfKJ2Cj7zWweGu2LyHb5eM51MxThMQKKz8U/QnRB0IifjmLLv0u2qOWaIlmOGy5drd5PBl8m0ew67cSHjXZEzng10k85xBqLTuN36SJBI1fzMK8MakXsx35hLFfT+mzZEov2mRuvcNOlC9ZJDaemMaarZD8KiJ5joET4dbMAjxpGvjcygH27BNT+1Oyc00ajmrUNl27EVOkKzJE6NmO74Ga4Jk2aYOfOnXYoChHqJ467E2N2ysagp2QvcvPsJ1BAZNncc5lhrnQB9shGQQKl2c6hxpoW9E8cpk4kF1z64Ih8CPzxxvLCCpBxUcutVfNVU3RF8+8ftSZP9tCqrWgqOsk5e7knkjFe6wKY3cZ5t/RZ2gRTmonBn7I/BI344ZcZmzGag0j/U7fk0t2Wo0bLWqYGGE+WrsRlF8M8Tvrf4yrim2guPoUFsvmf96l5lcZfLQMWnSUHLSrvl671p8+6qlhYLT6fADgrE3LTYelEurXFl4UUyeYEB0sFCxbExIkT0aJFC0ydOhXz5s3TedjbwoULERwcDBcXF4SFheH8edPz3CxbtgzVq1eHt7c3vL29ER4ebrB+p06dwDCMzqNevXr2fhkO4WPlyDIJlJAJmGrA2rt2rq0bi8+ghOih2VqlDPpZj4XeZe2R/2ryOSnH+2Lp3Vw1rZNxoFZw62KiZukPM5OdTpCuRlvJEc3f5j8b4Z9dkNb8apMlKwVvDwCFTKSQ4MLnPe4l2Y3r8q4G/fD4fEcdOV5H6G/IF9ZflC1t+rKEPUfkae87I/2DtnxMLK/P9idJJFZKZwBgUdPC+Rj1z1PNxSfNblNffAG1RP/iL6npaZGcYUSjEKHMM00ut3RZZzScROgGK1asgJeXF6KjoxEdHa3zHMMwGDBggM0Kp2/Tpk0YNGgQlixZgrCwMMyZMwcRERG4c+eO0dxPx44dQ5s2bVClShW4uLhg+vTpqFu3Lm7cuIHcuXNr1qtXrx5WrfrcP0cul9vtNdiKqRnbR0j+xlvW3Q5HZBEl749s+IjSqaY70mrLacXdVA/xbpTkSGIp1CEzU02Yu+D66lUvf55WRY3z8j4QQ4WyqUuhglhvv9yqia7BFalm1vrM0gzNJZkHgtbvKjlg0XEytJUcwa/KbgbLh0l1s/z/IDpj1XHS8TvhujGp6CnZjXHKzibXMd2skTUuShdc+qCXYqDN9/ud6CIOqcsL2obPhXyAwM7T+hZK52BSWnvEIgfnen0kuwyW9Rbvwgxla17HqS2+jEaqKEHnJCE3St+JLmKAZDsGpvXVWb5KNpP3PhiosU46Fa/hiZ/T+vHezhb4vtJIue5IW/bTVyQnEiFDGp4jp20LZkOCg6UHD4SddG1p9uzZ6N69Ozp3Tj/ZLVmyBHv37sXKlSsxYsQIg/XXr9dNeb98+XJs27YNkZGR6NChg2a5XC5HQECAfQtvYxkztuvrpTcXma1IoNJUJec2MiRWX3HmIY8s2sZPpkWYx/hV+rfJbdZIp3/+i7W0A7VpvkjAAMl2zFE2N7uf7EjR5ILyQRJewVvvONzlWyfj1/chA98+Ad5Iwlt4mHyeAQsxVHBDKt7BzeB5e32P9M2XLdD8WwIVZkqXCt6HsNxC+n/rbj1YathhNpCJR4TDkiay6CAW1iS2RDaH83kG6U2XQpoPl8lmo+TH5Ua/K47UUHwe/kwC2ihGI03vcqb72Rp+S1pLjgnKKDZP67sKAEFMHJ6w/jrLyjF3eO9PW0ZXgv0yw+sYF+3zSxHmiaZ50FiwJNJ7P2RQQgGp8MLa0BTpCnRJG4qLLr0BACU+Lkcy3PCbZIVDy2WM4GY4bSzLgmUz545LoVAgOjoa4eHhmmUikQjh4eGIiuI3RURKSgrS0tLg4+Ojs/zYsWPw8/ND4cKF0bt3b8THc/fpSU1NRVJSks7DHlqLj5hfyYaMXdj7incaLOOTHK2FVt8aU47JBhldbmrqEzFUcMcH1BB/Ht5t6bdPoldDo72fCy590F5yGNGffsB8NRWfwkOXtmiv1eG4k+Qf/C5dZGEp03lp5f7Jy5iei0/bStksACxmSZdgsIkUDHtkv+KaSzdenakzIzlfXbHwgISBGi4M/6Zhd+YDxknWYLTkL97beDApKCu6K7hstjLRDvOsWTKpr7ka0B/FxywrDA9c+aHKi/7DBXlv6J8NKopuo4ZWfz9jrOlv5qb1foyUrMc9eTtsk0/QLLOkCV7o5N7aAaHIzNmwidbN6xLpHPzn0lHwUH8+5WggOmv2fc9QQ3wVbcWf+94GMvEozDwW3B83M1gULK1duxYlS5aEq6srXF1dUapUKfz1F/+TjyVev34NlUoFf3/dSN7f3x+xsfxGBAwfPhyBgYE6AVe9evWwdu1aREZGYvr06Th+/Djq168Plcr0l3bq1Knw9PTUPIKCgix7UWZMky63y36FGCo1vNAG2iiRXLDI+Gg7U+35UfL+2CMbpbMsn4l9mKOf7HKgZDvWSqeipZjfydPYaTCjNmySdLXO8ubiUxY3nwHpTVf1Rec+HZdfeFhWFIPizCO0EJ9AfxNNHRlT4PDpTF3CSJ8PWyvMCJuSxwPvcUDvTjyUeYaxkrUmJzCuwNxBZ8lBdJPsFzQzfXMHTXAsdI5DRxFBbVGtIB/5mef4T94RYyWmh/N7Me8h0UtVMFW6Amtk0+ED+9zMrpFNR33ROeRhXqKnZC/EeklLrfnN81VUZHwE6in5ALTSO5dpjwquJ74AwHZ5tbQtks3DGtl0g+XZTfzetM+XFUW3kYvJnME0QgkOlmbPno3evXujQYMG2Lx5MzZv3ox69eqhV69e+OOPP+xRRpuYNm0aNm7ciB07dsDFxUWzvHXr1mjUqBFKliyJJk2aYM+ePbhw4QKOHTtmcl8jR45EYmKi5vHkiW3nXTOln3gHjsl+QU4bdOLMEMK8ML+SHiHDVS1hKljyYxIMAixbnaCLih7jW/E1zJDy649VU3RZUPJAITVgD13aGixbLJuLHuLdvObkyyCkM745lmagFkI/5YGxO/O8TBwWSuegJHMfV126G8wpGCkfii6SA7jg0ge1RYaTwsq1aqFEYOHK8OsvlhmvP7NY2imYayshtXtCDZZshohh0cVMP7rREuMZrr05Jh62RgDzFotlc+FnIjCvJnDEnCW8TGScz8O8xnTpMrQX/2PRVFahzDObToFVhonBNRfDPoz6hkk2OW2ndcF9lubPn4/Fixfr9Plp1KgRihcvjvHjx+OXX36xaQEz5MyZE2KxGHFxuhfLuLg4s/2NZs2ahWnTpuHw4cMoVaoU57r58+dHzpw5ERMTgzp16hhdRy6XO6QT+JBPeXT6aCUrs9ZR+WDNv7m+pNoXLj45kr50oaIXiJQPxR5VWKYd03Q/LuO0PzP9wEPEY+Z2bRMtSFCaHSloJj6JfaqKgrcFgBKiz/0jm4pOIhfzBj+Iz6Co6Akaik2Pgs2Q3hSpS7s5kQWDCjxHU2adMTv246j3QPuz5kqYaeq8xCc5ZlaV/rtmkQ0fYSycnSRdjTzMK0xVtuMdhFQRXccG2RTEqAMRrvj8G2olPoqGorPonTYQ7+EC7W+Eue9GT559ID2YFEGd2jOT4JqlFy9eoEqVKgbLq1SpghcvhNdS8CWTyVCuXDlERn5uy1Sr1YiMjOScwHfGjBmYNGkSDhw4gPLlzY/mePr0KeLj45ErVy6blNse7FW9u0FmeoiqUJbcHYSLorFKalh968y+F59zdBFM4voETsqF3dSU0gpc+JoiXY4J0jU6GamFqCj63Fn2D9liDJNu0jQdWkq7hmibbBzv7Zz1btcSlgY9fDK/29sMC2qSfxIfskNJnIMbk4rl0lm44dIVJUyM1KsiugFXfDSarFZ/dCoANBGdBmCYZ2+6dBm+FV/DKMl6XJD3wRCJ4bb2lkldpI0SHCwVKFAAmzcb9mPZtGkTChYsaJNCmTJo0CAsW7YMa9aswa1bt9C7d2+8f/9eMzquQ4cOGDnyc/+L6dOnY8yYMVi5ciWCg4MRGxuL2NhYJCenV10mJydj6NChOHv2LB4+fIjIyEg0btwYBQoUQEREhF1fizWywom7uAXD/pfLfkctMb+OgcQ8R8/onTGZrP5UDY6kHSwVEvFvRjXXefZr4MHw7+NlL6b66HApJnpk13Omo39nGUFQd/Feo8+XFD3EVtkEo88B6RnbD8mGos2njtbm3qu2kiPwZRLRT6uFIytck6wluBluwoQJaNWqFU6cOIGqVasCAE6fPo3IyEijQZQttWrVCq9evcLYsWMRGxuLMmXK4MCBA5pO348fP4ZI9Dn+W7x4MRQKBVq0aKGzn3HjxmH8+PEQi8W4evUq1qxZg4SEBAQGBqJu3bqYNGmSU+dayuwOcP/IhmKTqpagbfg2b3wtHHFCdfRJ3I1nf6DM5GnxBf/LvxiYU1v0L9apvtP8bSzRo76SzH2LaoNsSQQWpQTmGRPCWQIFrrx2xUWmR7xuk42DP5OAqaIV+FtlvOuJJRiowVo34N6pCA6WmjdvjnPnzuGPP/7QTHtStGhRnD9/HmXLlrV1+Qz069cP/foZT7il3yn74cOHnPtydXXFwYNZL61/XXG0+ZVsqJDoGcaIjHeeJM5L+xTuLCf0rOpLqlmy9LugPxx8H0dW+4zj7DaRDy4zlRHdc3QRMoUXY9lEs/56g0aqi68J3oex79Rx2S/4TjETqZB9EX3+BAdLAFCuXDmsW0cXT0KEkHLkirEH7ZolZ2oKy4oyZov/mrFg8L0oCgHMGyxXNTS7vpCRm1mZo2twbSkP85JzAmJTihjpS5hX9Ao1RVdwUF3BFkVzOMHB0r59+yAWiw369Bw8eBBqtRr169e3WeEI+VL0Ee/CLxLD7ND29eWcxIntaOfbEULCqDUT8ibxyOSdGXmGnIELY7sh9o7mA900C3IokAqZFXtMr3EqKTI9ilEIUxNLZwbBDYojRowwmrCRZVmjU44QQtJHnUgFZue11l4zzSTk67TABhPl8slH9otkm9XHyQqmShyfPNhW9DvxW5umJiO2yW2jRMaOJDhYunv3LooVK2awvEiRIoiJibFJoQghhNhHHgtrloRqLLbFJMnOz9RMBFnRZL052TqKrcup9yUlcxUcLHl6euL+fcMqtZiYGGTLls0mhSKEEEJI5son0p170tqBIQFOOnWJJQQHS40bN8bAgQNx797nEQYxMTEYPHgwGjVqZNPCEUIIISSr+nJGkQoOlmbMmIFs2bKhSJEiCAkJQUhICIoWLYocOXJg1izD6QUIIYQQkvV4MikYITE9zdJO2Wj8IDLd3DpGuh5bZePtULLMJ3g0nKenJ86cOYNDhw7hypUrcHV1RalSpfDtt9/ao3yEEEIIcZBekt14wvoafa6M6D7myxZwbl/ehgmKHTndiUV5lhiGQd26dVG3bl1bl4cQQgghTmSydKWji+BwvJvhoqKisGfPHp1la9euRUhICPz8/NCjRw+kpjrf9AaEEEIIIdbgHSxNnDgRN27c0Px97do1dO3aFeHh4RgxYgR2796NqVOn2qWQhBBCCCGOwjtYunz5MurU+TzJ3saNGxEWFoZly5Zh0KBBmDdvnt0n0iWEEEIIyWy8g6W3b9/C399f8/fx48d1pjapUKECnjwxnB+GEEIIISQr4x0s+fv748GDBwAAhUKBS5cuoVKlSprn3717B6lUavsSEkIIIYQ4EO9gqUGDBhgxYgROnjyJkSNHws3NDdWrV9c8f/XqVYSGhtqlkIQQQgghjsI7dcCkSZPQrFkz1KhRA+7u7lizZg1kss+zEa9cuZJSCRBCCCHELiTKFPMr2evYfFfMmTMnTpw4gcTERLi7u0MsFus8v2XLFri7u9u8gIQQQgghcoXj5pqzKIO3MT4+PlYXhhBCCCHEGJnyncOOLXhuOEIIIYSQTMeqHXZoCpYIIYQQQjhQsEQIIYQQwkFwsHTixAkolUqD5UqlEidOnLBJoQghhBBCdDEOO7LgYKlWrVp488awR3piYiJq1aplk0IRQgghhDgLwcESy7JgGMPoLj4+HtmyZbNJoQghhBBCdLEOOzLv1AHNmjUDADAMg06dOkEul2ueU6lUuHr1KqpUqWL7EhJCCCGEOBDvYCkjvxLLssiePTtcXV01z8lkMlSqVAndu3e3fQkJIYQQQhzYZ4l3sLRq1SoAQHBwMIYMGUJNboQQQgj5KgjO4D1u3Dh7lIMQQgghxCkJ7uAdFxeH9u3bIzAwEBKJBGKxWOdBCCGEEGJrTFbo4J2hU6dOePz4McaMGYNcuXIZHRlHCCGEEGJLHu8fOezYgoOlU6dO4eTJkyhTpowdikMIIYQQYihN4uawYwtuhgsKCgLLOq4qjBBCCCFfn1Spp8OOLThYmjNnDkaMGIGHDx/aoTiEEEIIIcZkgdQBGVq1aoWUlBSEhobCzc0NUqlU53ljU6EQQgghhGRVgoOlOXPm2KEY/C1cuBAzZ85EbGwsSpcujfnz56NixYom19+yZQvGjBmDhw8fomDBgpg+fToaNGigeZ5lWYwbNw7Lli1DQkICqlatisWLF6NgwYKZ8XIIIYQQ4uQEB0sdO3a0Rzl42bRpEwYNGoQlS5YgLCwMc+bMQUREBO7cuQM/Pz+D9c+cOYM2bdpg6tSp+P7777FhwwY0adIEly5dQokSJQAAM2bMwLx587BmzRqEhIRgzJgxiIiIwM2bN+Hi4pLZL5EQQgghToZhLeitfe/ePaxatQr37t3D3Llz4efnh/379yNv3rwoXry4PcoJAAgLC0OFChWwYMECAIBarUZQUBD69++PESNGGKzfqlUrvH//Hnv27NEsq1SpEsqUKYMlS5aAZVkEBgZi8ODBGDJkCAAgMTER/v7+WL16NVq3bs2rXElJSfD09ERiYiI8PDxs8Eo/Ge+4zmyEEEKIMzkQthb16je26T75Xr8Fd/A+fvw4SpYsiXPnzmH79u1ITk4GAFy5csWu2b0VCgWio6MRHh6uWSYSiRAeHo6oqCij20RFRemsDwARERGa9R88eIDY2FiddTw9PREWFmZynwCQmpqKpKQknQchhBBC7Cc28YPDji04WBoxYgR+++03HDp0CDKZTLO8du3aOHv2rE0Lp+3169dQqVTw9/fXWe7v74/Y2Fij28TGxnKun/F/IfsEgKlTp8LT01PzCAoKEvx6CCGEEMLfhzS1w44tOFi6du0amjZtarDcz88Pr1+/tkmhnN3IkSORmJioeTx58sTRRSKEEEK+cI5LHSA4WPLy8sKLFy8Mlv/777/InTu3TQplTM6cOSEWixEXF6ezPC4uDgEBAUa3CQgI4Fw/4/9C9gkAcrkcHh4eOg97uKfOZZf9EkIIIYQ/wcFS69atMXz4cMTGxoJhGKjVapw+fRpDhgxBhw4d7FFGAIBMJkO5cuUQGRmpWaZWqxEZGYnKlSsb3aZy5co66wPAoUOHNOuHhIQgICBAZ52kpCScO3fO5D4zE+vAKJoQQghxLlloIt0pU6agb9++CAoKgkqlQrFixaBSqdC2bVuMHj3aHmXUGDRoEDp27Ijy5cujYsWKmDNnDt6/f4/OnTsDADp06IDcuXNj6tSpAICff/4ZNWrUwO+//46GDRti48aNuHjxIpYuXQoAYBgGAwcOxG+//YaCBQtqUgcEBgaiSZMmdn0tfDhyhmVCiGXULAMRQ79dQr4kgoMlmUyGZcuWYcyYMbh+/TqSk5NRtmzZTEni2KpVK7x69Qpjx45FbGwsypQpgwMHDmg6aD9+/Bgi0efKsipVqmDDhg0YPXo0fv31VxQsWBA7d+7U5FgCgGHDhuH9+/fo0aMHEhISUK1aNRw4cIByLBFCBNumqoY/lD/ilPxnRxeFEGJDFuVZIrrslWfp3tgiCBUZ9g8jhDin4I8bAADR8p7IwbxzcGkI+bIsCl2CPu3b2HSffK/fgmuWWJbF1q1bcfToUbx8+RJqte5Qvu3btwsvLSGEfEGovyGxpVvqIBQV0ahrR/6qBHfwHjhwINq3b48HDx7A3d1dJ9+QpydlnCaEkK+1un69so6ji/DFiVYXREuF/RI+E34E1yz99ddf2L59u85ktITYg4plIHbSjrILlY3QV7LL0cWwuavqEJQSPbDrMSp8XIQd8rHIw3zJedm+zpqlUcquaCeJNL8i4W1kWje8gxsiUqfhoNxwWq+viSOvBoJrljw9PZE/f357lIXoyazRcKU/Ls2U4wBAs9TxvNctnbrM6uO1V9j+5PKfOjdmKvnNG5jVXFYXsPsxXsELT9SGE19baoCin832ZStj0zpxPn9ZTedQRzmkKpdpx7JFrrz/2DwAgDtsXqv3RSwnOFgaP348JkyYgA8fHDdHy9cis4KlRLhjSpptO82ZcoktZPK5V+znZty3rDuS4YZnbA6rjndSXcqq7SNVZQ2WNVNMsGqfzmyBsomji/BF2K8OQ8mPy40+l8pKsEz5fSaXyP4OqCoAAHoqBtr1OImsm1Xbn1bbb7J3fXvUtsjXZ/tayljW2+b7/NIJDpZatmyJt2/fws/PDyVLlsQ333yj8yC28wb2yQxuzAqV45tVB6X11vx7o6oWAEBkg4DxhjqfRdu9Zd3RNW2ozrJFykZIRvrJuo1ilNVlcyYHVBXwEp9PokuVDe12rGTYLjVHMdEjm+3Llt7B+EV9jSrii+7TdFBdEU1SJ2r+/kkxkve2rRXmc/UJ7Tx/S61bI3NEbXgDZC/znfDm46K6EIal9XB0MSzCOLB1W3Cw1LFjR0RHR+Onn35C8+bN0bhxY50HsR0lxJp/X1CbrpHJcEJV0uJjqbSOBQDX1MEW78sW1J9OiCJYP3FiJ8VwTE5rK3g7YzV7i5SNNP+OysQ7VEf4n6qq3fadwLpzPt9fQNOaKz5aWxyjXrA+dtlvlLoYzqmL2mXf9vaGdcdjta/R5/apwjT/VmpdWt6y2Xnv/6y6GF6z3DeJQoOlRorfdP5+zPobrJPAZsNTNqeg/fKh1OsWnJFaAkhPXtoodZLO83OVzRDHetm8HBmmpbVGC8V4xFHNkmCCg6W9e/dix44dWLx4McaPH49x48bpPIjtXFaHav69RhnBuW6Uqhi6pw222bGXK3VrmiwJNmzBFjVLr+CFZarvcdhIkxoXBaQ6f/+s6KOpVRJqSFpP3utuVtaw6BimJJlotphn9q6X/3vfVvGrwTI+Ab4pr2E4svbfTOhPpS3aivJn0G5a1hYPT5T+uBS1Un+3+hi28JxnYDgqratBsNJeMQLNU8dhl1aT0wut5vOMPjd8mbtBUgsMltJ4jGOqnfo7+ikGCNqvUAlsNp2/X8AHV9nP5/inbE78oWyB5nZs5l+jqmu3fWdYq/yO97qrzFzX9DkyK6TgYCkoKMhuE8cSXX8oW2BGWiuEp87APnUY/lKGm1yXBZAKmc2O/T+1bq3CMpVhHws1a/860clp7cyuo2DFZtcBgMFpvfFbWjscUvFrLtY/uVnzau+q+U8yPUypG1gNFVhlnszqNnG1MxLIAMBsZUudv/Vr0oQEqnfUQRio6KOzrINihM2aKlukjkVTxUSjz91nA21yDH3GXv0GZW3EsV6IVvObscBYLcgFdWEA6X0F+VzIM0OV1Pm81mPAGrymZNYV0WxhaP9C4uGJpqkTEJE6zZbFBGCbHFbazYTp+wSessZrzPSlsHKLjsm3DypXOc6oill07AwfbNj8bcyItG6YpGzPa93mqeMwWWn+/O4sBAdLv//+O4YNG4aHDx/aoThE20fIsUjVGDFsHqghwhhlF5PrWnoCWa6sb+IZ609IH1mp+ZXM2KmuhvIfF3OuMyitD+fzGRLhjuWqhnitd7dfJ3Umr+2NneyOqkrz2tYaW1Q1DZZx3ZENSeul8/c1lt/IK/3Xd5/lP5KHQfpn1Uurc+8HuCBKXdxos4LQ7+tFtojJ5x6yAYL2xZexMm5S1URY6kLcUQfx2scH9vMNTP6P61D442q92kln6b2k+1q3qaqheuofBmuJwPKu2fmXLYg7bF6d71VPxS9G92u6JOkGKXrhv083HAc/dSS3xmVWt5aSBYN48Gsu7JNm2VQ2+q9L//vFGrn5vKnX33Ka0jYDcex1mxup+ob3DUA0W9igmVKb0RGjDuy0JDhY+umnn3D06FGEhoYie/bs8PHx0XkQxzB2yjXW9p+qF8Bs+tSR2hLmJgvNuIO2lrEmGW13Wf61NoBuUNBHMQD32NxokTpW0HYZOqcNw588OkLbI6OzqUBNu5RpPGvdtBX7uBKlPy7Fe7hiKs9Rklx3zTvt2PcJABSQ4BdFb6jsUNOp34zGfPrvA54BWp+0gbivDkAvxUCoITKo/bX1iNd9qoo22c88ZTM8N9GHR/+7LOQ13GaD8MRInyFz+9uu/hZtFKMxWNELk5Q/8T4eXyyYTMiMxf0+aT9b9ONKDFD0xfeKyfYtko3Z8jz3u17NN+DY7GWC64DnzJljh2IQS0SpiqGy+KbOsgGKfpgnWwAAqJH6B264dNXbKvPuZFPgglRWAjmjFLytPaeL0N7zHTa9hsBYzYV+CYyXiMFs5Y/oKdlr5pi2f987pw1DXdVFLJXp3qlrp0tQf7of+lPZkHcZU7Sq6v9U/YAj6rI4JB9mpjSmX5+ln2XL1DEYK/0LY9I6m113h7o6riryI1I+1Oy6J1Ql8a34mtn1WDBYqayP4dKNmmUZ/WnWqCIwSrrB1KYaN9hg1FbMNruevvnKJsiOFHSS/CN4W1tgwRgM+gAs+x4L/fxNHSMentim/tZgeU/FL/hTxl1blUFov0VbMvcuaL9PH+CCXWrb3WQsUzbA/1RVNH+/h2VNiZnJ2Pfgrcz6vFWWsmg0HNeDZI7jqlJon/Y54eLaTx33Dqs/98fR76AMAJ3Shuv8zefUt8REThg+fZZaK8bwOEJGWT7vz545prQ7kAo5kTMmatL49BWzNvS7o9btJJv+/jB4pnf3f1kdqhPsZHzCfF6nqff8Lo8OukJfn3Z5TI1COs8WxfeKKfiXtbx/kL6nbE50SRuKoWk9MEDR1+D5bgrdQRJLjPTVA4z/tixhqsRPTPRbMdckPcvI3Thf3RWDDJbpfzbG+izZQjLrgulprT8dQxhzo+d0jgNXgXu3HVO/r9FpnfGBlemkTjHF1PeOq3Y7lZVisvInXNdqjn/C+mN2Wguzx7Ol33j0P9Wm/z1rmDoFKTLHtV7xCpaSkpJ0/s31IPa1VZV+ZzVD2RpKSBD68S98m/oH/lGnt+OnwAVNUifih9TfjLYdWzLc/aTaeEoC7Z/+UzYnNitrYLHyB511brKGOY5Mndz4BkgtUsfigZq7Kp+LWutr/0qrP02rVO7AzpoAju+2k0ycUDophmOJ1ntr7K4f0E03oV8Ca1T4uBBNUy0bpWPs4mrLUDhj/3wu4tVS50EJCbaoahrcuatZBofVn7M731HnAat3irR1EG9qf/fUgUZfz2t4cg5x1+/sPiGNX2dbADiuNt//jgGLucpmBmWyVonUlVisamR+RSMyaoczjEjrJngfQj5VUyMczdEfMJHRR2md6jsUT135qZM8t9ssv75yfMxTNTO/0iemRtQKsUElbN5A/e//DTbY6jJYg1ew5O3tjZcvXwIAvLy84O3tbfDIWE7sa0haTxT9uFLzxVFBbJA35DJbgHenXn41DubFsd4YpuyJq1qd8v5j8yAVMoN+M+0Uv+KqOsTicl1ki/Aqt6nAQ6W1rXbiwHOsbXLfVEudi+9SZ2CdBZOKxps4Eb9ADkxTtsHMtJa4rw7AQmV6TjO+F28+a3G9o6/gzVnDw3XHbs8mVd3j2Eaj1EmYo2yG5SrDu3VbB0umOkuLwJq8uExI68B7/4fU5S0qVwb9TscMgN3qKqj0cT5+UoxEf0U/o3mLhNDvxKx/bjB3Y/Reb4TXC4uy/jNGP9tvjXRGT7HDiDI170Ye4b+ln9MMa1CFasMjWShg+jf4lM1p9n17ope/y9JRh/bCq8/SkSNHNJ23jx49atcCEXMYuw3/HKDoi2nS5eiVNlBnOZ/EkBknGu0TTsbUGWmQQAqVZvkdNi+6KIbhootutbOQZrh96jD0E/0P99S5TF6MVxi52AHALSO1XXwIHfo7Q9kKcqRhh7oa7231m9X0LVQ1wUJVE7NlnJHWEsOkmzEirTsAYKWyPlqLj8KbSTa7rSW4ToTG9qr9mbEsY5Oemx9Z61JnZAxYuMqG4qoy1Og62sVcp6yDnySRSGHlmK5sjUcWBA1PWONz5DFgTTZ/Cvuc+K+r85lkHEuv6Tnj2LHIgVg1v6DEXHkbKXQTM45WdsExMf+ccdZ0ODe1jwyPWX9cVwejhOih4H3q0y+Xpb+2borBWC7jl5/rodofB9S26PTP96aM+4fcRjEKf0gX4dc0/b60hi6xBXFZnR9lRPd5HdveeAVLNWp8TpIXEhKCoKAgMHpD+FiWxZMnT2xbOmIXF9SFUEH0n8HyXeqq2J1a2aDpwZT0H4bpH1FGX57T6hL4ThzNO/EdH3OVzXFDHYyz6qLwZRIFbZvMmq4F6aAYjrWy6Uaf43M9186DkgR3DFWmD+P/hjF8vwGgn6I/rrL5kZd5iVDmOS5wDJEXYpGqCf5S1dXUnL2CF75JXYIHLqZHEgm5yBxQVUA98QWD5cb2sFNVDX0lu0wf18yoSm09FQPxp2yO0ediYfzi/Y51RXbG+FyWo9M64zfpKt7H136PJivb4QGbCwfV5fHURNDDZ49cS2NZbwQwby3ctzBpkGC3qhKy4SNnEGcN/YvpO9bVYPh4ol5+s+2q6lYd09ZYAHVTp6ON+Ag6Sw7y3s4WCXYB4LC6HBqmTsZeufkcZqk26ltnK1Hq4qiUupDn2gxGpXXVeZ2ZMWbRFMEdvENCQvDq1SuD5W/evEFICHfTCsl82h2DNyprAgA6KkaYWBtGAyUhX09jdxZD0npiRlortEgdb9V+tKVBgv3qMLy1YP48rhP+CY5+G3wuFPr9J8zZo66Mx6w/TqlLYo3KMHfSEr0+YIZlMk1/bjJjn612U+UbHnlmGqZOxoi0bga1jxmOqcvgnjoXtqmqaZbdZfOg3MfFmK9sgmGfarrMeW6iKeWguqLOlBGA8fw02lYZeV8zrFPxzzYM6L7fH+CCFaoGVgRKHMf5FEBeM9JcbauUHMb0TxuALmnDkPFK9d9bc+lCbEH7iAMVfbBIxX8arbvq3PhgQfONsVeVkYHe2HP/sUGYoBQ6oCl9T7c+5ejabcUku9rNdrbIZ2dvmTUpvD0JTh3AsqxBrRIAJCcnw8XFvtlBiXBtFaNQW/wvzqqLau4WUyDHB1YGV0bBO2utMUfVZfCd+JLZ9RLhbnDCM/fjEdJenVl9Yqz5wVvSRAMAZ83MIWbtSWiXqirGSNcDAA7wyNFzgw3BDZXpm6JUyFBHMQv6YVw8PHXypmiX2lgz3CMbJJo8qiqNeB6dj1NYOdyYVIMJV41hGNbm2TcyUoBsUNZGW8mR9ONwHMSSGwRj7qlzIVT0wib7spSx16m97IS6lMnBDMawAP4zknctI13EOq1ZEF6xHvBlkj5tZ5gqQchx+ch4Xa0VY1BJdMtmE/qWSF2BoZJNRp/LrHPj5+PZmiMzK+niHSwNGpQ+rJRhGIwZMwZubp/vWlUqFc6dO4cyZcrYvIDEOvHwNJIBmkGZ1KUQQc057P2KOj+KME9M3slqV/Ha6is9Nq0j6okuYLWqno32KNwpVXFUE9/AXyrT08sIFQ9P1E2djn/kw82vnIm0T6ZC59wyzbr9nFSVsEkpOn9KkzFIsplzvcaKSegu3strdJA97pDbpI1G9rQUvIMbr2BJCAYsXrA+yMW8scn+TqhKmV/JTHnMr/OZJe9CAj5P0pxx09UpbThypCXhFbw0z71ivTXBUob9qgqo/6l52VyNpVAZe0uEOw6qrc9CnoErC7Yt/ZD6G8ZK16KbYgiuuHBPwcQ3l5k2Pp8168AaKt7v8r///gsgvWbp2rVrkMk+X2RlMhlKly6NIUOG2L6ExC745AZqopgIKVQGuT0uq0MRxLzEDGVrfC8+p/OcNSf5t2x2rFVHYC1Hs8krI2kHYm08O3zXtKEoqHyK62x6DUpG8MRnmgWu1/+fDYf92oOz3MPt4dE8cUZVDFU+JWS19vR5l81jMB9fZtNvMv38PbL+U1mnDMdQKXfAaIpUK6FsqY9LkaQViPDFVbthrmbJ1LZvWHf4aAYrMDrrazc3ZyRfVEOkEygB6TdmW+UTdY4zIK0/7oo7fFpmnGWj7WwbaGd2jREDFtfY/PhRMd7i7c15yvoiL9K7+Ky3YCSxvfEOljJGwXXu3Blz586lyXS/AixEUBjp5zJf2QRH1GV5dwQ3tXdtU9PaWJxH4x3cUCN1NhSsFFEu/a0oU7pUyHQSuP2U9ivkaWk8k09mrbZ5x5XWcOQVkD5axlzTIwC0S/sVD8S2n/bCnMz6fG3VGRgAlqh+wA02GE3Fp9BYfEbQttqdyy0JlADj71k8mx05mHeI/tQvyBRrg4LGqb+ZfE57QACr939Txy71cZnOeSBGHYgCoue8yhIH+6XW2aOqbDRD/2wlv8STY9M6oijzGG0k1o12t6bp8j1cUPHjQrBgtAJb/dGYWaiD96pVqyhQIjZN1hepKos/Vdwdmc15xAbgBXIg8VPytGvqYJPrCv+5MbwCJT775tvBOcNb1rILlCkZIxLvqQ2nDXCGQC9KXZxXEG5doG65zH6P/tFKkqltvrIJNihrm92eQfoF7Ji6DEZakKzR1jICkKaKiZivbIJfjE6CLaypDvg8ECJjFvvgjxuQ/+M6PAd3Kg4+tIOmJOiO1LvDI7t989RxOK0qjs4Kc1MGWe4am99gHse2il81yYpN+TF1LOYqm2KDqg7nxNmJeq9b3wJlY8xTNtG8P/q/k6tq46k4dDF4CW+DGkBnIbix8/3795g2bRoiIyPx8uVLqNW6OXju33eOnAjE9m6o86G46BHO8bjzd5RmignoJD6IRUr+I2hsydzFdLOqFqZIVkDCcOeuGqjog3xMHK7ozY4u9Hj62ihGo5t4H/78NI1HZlfn28NbrVF8b1l3zlxS1kph7TuI5YyqGAqJnuK8Oj2FxF5VJcyULjVYL6OzfEYfp6zmMetvdKJUwLI+S9OUbTBP2VQn3xf/RI+WZ5m/qQ5GQ/F5znWi2cJol2Z+mL8Qxn732oN1zqsL44zafN+/C2wRXFCmf9fiWNM1X1yTH09Ka2cyp10GS7KqOxvBwVK3bt1w/PhxtG/fHrly5TI6Mo58mX5QTIYUShO1LJl1x839fbvH5sYYZZdMKotlUuACD6RwrrNTXY3zeVPMBU+P2ACd98dRdUm2CNIGKPrCn3mrk7wxSl0MDcxcvKzxr5ng1Vpt00ZBDLWmOeMjzxrNL4nud9j49+Ssuijqiy/gjVbNq9DM2slaga+x5qMv4UZCGOOv9x+V8drNDNoTd5uSwCMtiePrtbkJDpb279+PvXv3ompV282ITLIGNURmm6P+41EtDej+eDJ7csuHVk7PwOWFjTub29sHrdnHP2TiTOS2ODEam5Xd2H6v8GoC4MveF1DdIezWvk8JWgkenf1ilIFPB+8Rad1xU50POyy8qQDSz0H9Ff2ggEQzj6bxGibTn7nQvGr2ZH3CUNsd90sMNAUHS97e3pqpTwjJkPHTiGHzoI1iFF5qTVBrjPYkv6Ynf7WPaLYwhqb1wAO19bl8MnRSDMN3omisUDWw2T4tIfQk9VErQNKe1y+rMvb6I9XfoK9iAG6x5vMocdGf4zAzWHvRMdUpu6fiFwyTbLRq35nB1AU8Ee6YL2AiWFN2q6twHDv9vb/P5kJpGO9eclj9DUakdUNh5omgbN7O6DiPGiJjjH1DbTXljDP0o8wgOFiaNGkSxo4dizVr1ujkWiIkQ5S6uKD1Y9SGSeTszTD3lHWOqcvgmLoMz7VtdwJ4aIPkjSU+LocL0gw6r2YW296FGj9171VXsniPr1hP+DKJiGa5R27ZB/d70zR1AsZJ1xidPytO74ZF+wbljMDfqDUUkCCVlUDOKHml+dBuTkvLpBxCXCakdcAHVo4tqhpGnmWwUVUbzUQnMr1ctmYqsDb36zQW0DjD52Zrgl/R77//jnv37sHf3x/BwcGQSnVz8Fy6ZD6jMyFA+om+pvgyVqjq897mS6zetUYi3FEtdQ5OyQcCsOxOLBlusF+XaOOy0ufYTDEebcRHsUrpuESppvzLFsRuVRVek40qIUGL1LGQMiqDvE72xaBU6nKIoDbI2WZMErKhn6I/lBDzHoVqTwnIjl+V3B2Us9L32daMnXP+Un2H2uLLgvYjtAk0swkOlpo0aWKHYpCsaqeqCpqIz1g0+uxftiD+VRa0Q6m+LvaYm0yID6zjL2gZ7FFp/4T1xwxlazvs2b4eGBkKfpEt4pDOS0KDHj6JSe1NyGg6Y7jSl1jL0umTLBHPcnfONtaNwpJRozFsoOBtMpPgYGncuHH2KAfJon5J64Mpae3w0o4J14hzapE6FkOkWzAuTeiEoroWqRpjumgZdqssbyrL4Ex3oo62W+X4gCMrExJTqowEVpfU9rsRTIELynz8U6e565BWTq4VSv619abMTGuJb0R3Md3MjYK5QT09Fb9wPt8sdTzqiqOxQNlEaBEzlUUNiwkJCdi6dSvu3buHoUOHwsfHB5cuXYK/vz9y5878/ifEcViIKFD6Sl1ki6C1YoxF22oHNZtUtXBOXQSPbXC3/MrMwIIvkakA0VzgyCewvK8OQH5RrEXl+pocVFdAjDoQ59WF0dbKLNh86Q/HT4UMoR//Qi7mjcUTpFf4uBDVRdfwAXLsV4cBKu71L6gLwVyvJnPz4F1iC+GS0nh/wCzdwfvq1asIDw+Hp6cnHj58iO7du8PHxwfbt2/H48ePsXbtWnuUkxAAWWf4M5fVqggMkOzEYZVtZh0H0vPOVBLdwnql7Sb/zUwPObIHCzFX2QxBzEvsUFk+pDyrMfWbMHehcaYLkTMSUkuZChnCFTMBMJpgKTNTcWRQQWxxoAQAr+CN7epvea+fyBofFKKgDt7AoEGD0KlTJ8yYMQPZs3+ObBs0aIC2bdvatHCEfInmKpvjpKoUrrK2G6rfQTECIcwLp8r74ghJyIYeaYMdXYxMZeqiTsGQdYQ36aavPzqtM5qKT2GRspHtC+UkeioGoovkAMakGU8A/C9bAHtUYTapLXYWgnuwXbhwAT17Gs7QnTt3bsTG2q+69s2bN2jXrh08PDzg5eWFrl27IjnZ9BieN2/eoH///ihcuDBcXV2RN29eDBgwAImJiTrrMQxj8Ni40fnzj5CsSwUxLrBFbDrSRwEp7rB5Yf+kibZBl3HhXrE0J2dm4pPmwJh1qu/QXDHB4omHs4KD6opopRiLF1qTEeti0C/t5yw5MMIUwcGSXC5HUlKSwfL//vsPvr6WV/+Z065dO9y4cQOHDh3Cnj17cOLECfTo0cPk+s+fP8fz588xa9YsXL9+HatXr8aBAwfQtWtXg3VXrVqFFy9eaB404o8Q4mxuqfMZXW7PTu2HP3UafspaPyFtVvOX6jtHF4E4EcHNcI0aNcLEiROxefNmAOk1M48fP8bw4cPRvHlzmxcQAG7duoUDBw7gwoULKF++PABg/vz5aNCgAWbNmoXAQMMhhyVKlMC2bds0f4eGhmLy5Mn46aefoFQqIZF8fuleXl4ICLBdNmdiPzTa6cuwW1UZHSWH8Ejt2LQHXzJzzXB8fku/K3/EbXUQr/m/vjRfYr+brMaZBmwIrln6/fffkZycDD8/P3z48AE1atRAgQIFkD17dkyePNkeZURUVBS8vLw0gRIAhIeHQyQS4dy5c7z3k5iYCA8PD51ACQD69u2LnDlzomLFili5ciVYlvskk5qaiqSkJJ0HIYS/i2wR1E6dhQjFdEcXJcsQQW10uaUdvPlIhQzb1d/iFbys3ldWQ32+HC8OPuiuGITWitEAAMaB98qCQ2dPT08cOnQIp0+fxpUrV5CcnIxvvvkG4eH2G4UTGxsLPz/dO1CJRAIfHx/e/aRev36NSZMmGTTdTZw4EbVr14abmxv++ecf9OnTB8nJyRgwYIDJfU2dOhUTJkwQ/kIIIRr3nTwJnbMxdZ1QmZhbkepghaOaa+dzSF3e/EqZwOJ6xqpVq6JqVcNZv4UYMWIEpk/nvrO8deuWVccAgKSkJDRs2BDFihXD+PHjdZ4bM+ZznpiyZcvi/fv3mDlzJmewNHLkSAwaNEhn/0FBX/coJEKIfZmacHq7qhp+Eh/CCb2mMqoZIcR2eAdLUVFRiI+Px/fff69ZtnbtWowbNw7v379HkyZNMH/+fMjl/HNLDB48GJ06deJcJ3/+/AgICMDLly91liuVSrx588ZsX6N3796hXr16yJ49O3bs2GEwl52+sLAwTJo0CampqSZfi1wuF/Q6ie3QnR/5Wg1I62d0+Qe4oL4FzZmX1AVRQPTc2mJ9sehcQ7TxDpYmTpyImjVraoKla9euoWvXrujUqROKFi2KmTNnIjAw0KDmhouvry+vEXSVK1dGQkICoqOjUa5c+uiMI0eOQK1WIywszOR2SUlJiIiIgFwux65du+DiYn6+msuXL8Pb25uCIUKIUwj+uAEM1GAFdjE1NjectknK9njG5sQetfXTzBDypeMdLF2+fBmTJk3S/L1x40aEhYVh2bJlAICgoCCMGzdOULDEV9GiRVGvXj10794dS5YsQVpaGvr164fWrVtrRsI9e/YMderUwdq1a1GxYkUkJSWhbt26SElJwbp163Q6Yvv6+kIsFmP37t2Ii4tDpUqV4OLigkOHDmHKlCkYMmSIzV8DIYRYSkig1CR1IoqKHuG4mRFs7+CGuSr7jGDOqqjp0rmVy+e4qbV4B0tv376Fv//nbJzHjx9H/fqfJ+urUKECnjx5YtvSaVm/fj369euHOnXqQCQSoXnz5pg3b57m+bS0NNy5cwcpKSkAgEuXLmlGyhUoUEBnXw8ePEBwcDCkUikWLlyIX375BSzLokCBApg9eza6d+9ut9dBCCH2dJktgMuqAuZXJJyoGc75yMSCB/DbDO9gyd/fHw8ePEBQUBAUCgUuXbqkMyLs3bt3ZvsDWcPHxwcbNmww+XxwcLDOkP+aNWuaTQFQr1491KtXz2ZlJIQQQsiXh3eY1qBBA4wYMQInT57EyJEj4ebmhurVq2uev3r1KkJDQ+1SSEIyUCU5IcReqBmOmMK7ZmnSpElo1qwZatSoAXd3d6xZswYy2ee5rVauXIm6devapZCEEEIIIY7CO1jKmTMnTpw4gcTERLi7u0Ms1s35sWXLFri7f7kTBxJCCPl6UB0T0Sa4t5Snp6dBoASk9ynSrmkixJYWKhsBACakdXBwSQghhHxtaKZAkiXMVLbGEmUjvIObo4tCCPlCqbTqD96y2R1YEuJsKFgiWQYFSoQQe2IhQuPUiZAjDYmgbiXOJkvkWSKEEEK+dFdYylHlrFxlxudHzAyOy/BECCGEEJIFULBECCGEEMKBgiVCCCGEEA4ULBFCCCGEcKBgiRBCCCGEAwVLhBBCCCEcKFgihBBCCOFAwRIhhBBCCAcKlgghhBBCOFCwRAghhBDCgYIlQgghhBAOFCwRQgghhHCgYIkQQgghTo9hGIcdm4IlQgghhBAOFCwRQgghhHCgYIkQQgghhAMFS4QQQgghHChYIoQQQgjhQMESIYQQQggHCpYIIYQQQjhQsEQIIYQQwoGCJUIIIYQQDhQsEUIIIYRwoGCJEEIIIYQDBUuEEEIIIRwoWCKEEEII4ZBlgqU3b96gXbt28PDwgJeXF7p27Yrk5GTObWrWrAmGYXQevXr10lnn8ePHaNiwIdzc3ODn54ehQ4dCqVTa86UQQgghJAuROLoAfLVr1w4vXrzAoUOHkJaWhs6dO6NHjx7YsGED53bdu3fHxIkTNX+7ublp/q1SqdCwYUMEBATgzJkzePHiBTp06ACpVIopU6bY7bUQQgghJOvIEsHSrVu3cODAAVy4cAHly5cHAMyfPx8NGjTArFmzEBgYaHJbNzc3BAQEGH3un3/+wc2bN3H48GH4+/ujTJkymDRpEoYPH47x48dDJpPZ5fUQQgghJOvIEs1wUVFR8PLy0gRKABAeHg6RSIRz585xbrt+/XrkzJkTJUqUwMiRI5GSkqKz35IlS8Lf31+zLCIiAklJSbhx44btXwghhBBCspwsUbMUGxsLPz8/nWUSiQQ+Pj6IjY01uV3btm2RL18+BAYG4urVqxg+fDju3LmD7du3a/arHSgB0PzNtd/U1FSkpqZq/k5KShL8mgghhBCSNTg0WBoxYgSmT5/Ouc6tW7cs3n+PHj00/y5ZsiRy5cqFOnXq4N69ewgNDbV4v1OnTsWECRMs3p4QQgghWYdDg6XBgwejU6dOnOvkz58fAQEBePnypc5ypVKJN2/emOyPZExYWBgAICYmBqGhoQgICMD58+d11omLiwMAzv2OHDkSgwYN0vydlJSEoKAg3uUghBBCSNbh0GDJ19cXvr6+ZterXLkyEhISEB0djXLlygEAjhw5ArVarQmA+Lh8+TIAIFeuXJr9Tp48GS9fvtQ08x06dAgeHh4oVqyYyf3I5XLI5XLexyWEEEJI1pUlOngXLVoU9erVQ/fu3XH+/HmcPn0a/fr1Q+vWrTUj4Z49e4YiRYpoaoru3buHSZMmITo6Gg8fPsSuXbvQoUMHfPvttyhVqhQAoG7duihWrBjat2+PK1eu4ODBgxg9ejT69u1LwRAhhBBCAGSRYAlIH9VWpEgR1KlTBw0aNEC1atWwdOlSzfNpaWm4c+eOZrSbTCbD4cOHUbduXRQpUgSDBw9G8+bNsXv3bs02YrEYe/bsgVgsRuXKlfHTTz+hQ4cOOnmZCCGEEPJ1Y1iWZR1diKwuKSkJnp6eSExMhIeHh832Gzxir832RQghhGRl1ydEwF1u295DfK/fWaZmiRBCCCHEEShYIoQQQojTc5WKHXZsCpYIIYQQ4vTEIsZhx6ZgiRBCCCGEAwVLhBBCCCEcKFgihBBCCOFAwRIhhBBCCAcKlgghhBBCOFCwRAghhBDCgYIlQgghhBAOFCwRQgghhHCgYIkQQgghhAMFS4QQQgghHChYIoQQQgjhQMESIYQQQggHCpYIIYQQQjhQsEQIIYQQwoGCJSf2bSFfRxeBEEII+epRsEQIIYQQwoGCJUIIIYQQDhQsEUIIIYRwoGCJEEIIIYQDBUtOjGVZRxeBEEII+epRsEQIIYQQwoGCJUIIIYQQDhQsEUIIIYRwoGCJEEIIIYQDBUvki8Ywji4BIYQQY/yyyx1dBN4oWCKEEEJIplvfLczRReCNgiVCCCGEZLqC/tkdXQTeKFgihBBCCOEgcXQBvhZqtRoKhULQNt5yIHd2sZ1KlDX0qhGKQv7uGLT5imU7YABYmdtTzQJvP6rxUemcSUI7VM6HtVGPHF0MQogNFMvlgZsvkhxdDKKHgqVMoFAo8ODBA6jVakHb/VhYjh/y+9mpVM4v0MsFIkYJKBMwvpZl74MNYiUALNJULCLvJ2P7rfc22J9t9awRSsESIV8IqYQafJwRBUt2xrIsXrx4AbFYjKCgIIhE/H8IkjfvkaJQ2bF0zi00wEPzb4WrA++0WBasUoHvZem1fNtuvXdcWQghX7TscrosO6Ms86m8efMG/fv3x+7duyESidC8eXPMnTsX7u7uRtd/+PAhQkJCjD63efNm/PjjjwAAxsjY8r///hutW7e2SbmVSiVSUlIQGBgINzc3QduKpUowaqVNypEVubi4aP7NSD46sCQAI5XD2weok1+FvXdTnLZJ7mvU7Jvc2H7pmaOLQQj5gmWZ+r527drhxo0bOHToEPbs2YMTJ06gR48eJtcPCgrCixcvdB4TJkyAu7s76tevr7PuqlWrdNZr0qSJzcqtUqXXDMlkMpvtkzgGI5FBKmbg7eL8P5s/25dzdBEyzawWpR1dBELIFy5L1CzdunULBw4cwIULF1C+fHkAwPz589GgQQPMmjULgYGBBtuIxWIEBAToLNuxYwdatmxpUBvl5eVlsK6tGavB+ppIRCIoBfbZcjoMA4CBKAt8lHWL+aN79RAsO/nA0UWxO1FW+EDIV0MiYqBUU82zpcrl80b0o7eOLoYB579FBhAVFQUvLy9NoAQA4eHhEIlEOHfuHK99REdH4/Lly+jatavBc3379kXOnDlRsWJFrFy5EizL/UVPTU1FUlKSzoNkntJB3jhyYC+vdb/WyyjDMBjVsJiji0EIIYJMb17S0UUwKksES7GxsfDz0x0NJZFI4OPjg9jYWF77WLFiBYoWLYoqVaroLJ84cSI2b96MQ4cOoXnz5ujTpw/mz5/Pua+pU6fC09NT8wgKChL2gnhyd3F8xd+V6PMomy8H+nVsKWi7+pVLYd3yxXYqFSEkq8jvmw3VCuR0dDGcVtdqxvvWEufi0GBpxIgRYBiG83H79m2rj/Phwwds2LDBaK3SmDFjULVqVZQtWxbDhw/HsGHDMHPmTM79jRw5EomJiZrHkydPrC6jMTmzOX7enB0b16FN5x6IPheFl7EvHF0cwagynBD7KprLg/P5QE9XuMq+7nxxXLxcpY4uAuHBocHS4MGDcevWLc5H/vz5ERAQgJcvX+psq1Qq8ebNG159jbZu3YqUlBR06NDB7LphYWF4+vQpUlNTTa4jl8vh4eGh87AHR3dzSnmfjIO7d6Bl+y6oXvs77NqyQef5Y4f2o23D2qhQIAA1SoViYLefAABdf/wez58+wcwJv6J0kDdKB3kDABbPnoaWEdV19rFu+WLUr1xK8/f1y5fQs21T1CgVCk9PT9SoUQOXLl2y8yslhFiqbF4vzudntCjF+fyXRuh5u2xeb/sUhNiUQ9t5fH194evra3a9ypUrIyEhAdHR0ShXLn2Uz5EjR6BWqxEWZn4ivhUrVqBRo0a8jnX58mV4e3tDLrdPrQ7LsviQxi93Esuy+MhzXT7kEpGgjuYHd+9ESGhBBIcWRMNmLTFz/K/o2m8QGIbBiciDGNS9Pbr1H4zf5ixGWpoCp44cAgDMXvoXfoyohuZtO6F5W/MBqrb375PxQ4vWGDFxOgr5Z8fvv/+OBg0aYMexC8jmnnXmESKEpAv0cnV0EZyao2+KCT+O7xTDQ9GiRVGvXj10794dS5YsQVpaGvr164fWrVtrRsI9e/YMderUwdq1a1GxYkXNtjExMThx4gT27dtnsN/du3cjLi4OlSpVgouLCw4dOoQpU6ZgyJAhdnstH9JUKDb2oN32z2Vzz0pwkZqvDs/uIsW7j2nYuekvNGyW3lepas1wjHvXDxfPnkaFytWwfP7viGjUDH0Gj9RsV7hYesc8T29viMViZHN3R04/f0FlDKv6rebfRfN4YenSpfDy8sLFs6dRI7yeoH1lNeN+KIYJu286uhiE2FybikE4dDPO0cUgxGJZooM3AKxfvx5FihRBnTp10KBBA1SrVg1Lly7VPJ+WloY7d+4gJSVFZ7uVK1ciT548qFu3rsE+pVIpFi5ciMqVK6NMmTL4888/MXv2bIwbN87ur8eZBedww8N7d3H98iXUa9wcAJDNRY66PzTFjo1/AQDu3LiOsKo1bH7s+FcvMWHYz/ihejl4enrCw8MDycnJiH321ObHcjadq4YgOIewxKUA4OEEAwGIcxoYXtDRRQAA1C7ijyF1Czm6GCa5SA0vhXl9hP8WhTLWhEk1Tc4py5xlfXx8sGHDBpPPBwcHGx3yP2XKFEyZMsXoNvXq1UO9eplbW+EqFePmxAhe67IsixvPbZeWQM5zziGGYbBj419QKpX4rnxRnfLIZHK8mzQDcq3s2nwxIpHBZ6RUpun8PfqXPkh8+wbDJkxFzXLFIZfLUblyZaSl6a73pcrt7YqH8SnmV9SS3YU6iBLjvN2cJxluSE7jsy04g5/rFML0A7qDieqVCMDSE/cdVKKvU5EA5+1qkWVqlr4UDMPATSbh/XCRim324NtfSalUYve2TRg85jdsOnACmw6cwK7IM9h88CR8/QOw/3/bULBocZw7fdzkPiRSmSZ7eQYfnxx4/eqlTsB058Y1nXUuXzyHNl16oHrtuihePD1Yev36tYB3+Ovi+WkkjSU1UgRY3+1zn8ee3+bHll6Vrd5nrxqhqFHIfP9ILpXy+1hdDgDw97D/iFozaeky1eiGRbGsQ3nzK/LwS7jz1ITxvdEl9kOfgBOzR9Zvmdj8R75nzx4kJSagaeufULBIMRQsUgyFiqb/v06DH7Bz4zr0+mU4DvxvGxb9PhX3797B3Vs3sHLRHM0+AvPkxaVzZxD34jnevokHAJSvXA1v419j1eK5ePLwATauXoZTRw/rHDtvSH7s2bYZ9+/ewblz59CuXTu4umZ+B1Hf7I5P20DsLyRnNs2/O1cNQYVg80FKbjMdlrtUC0ZBP+tqUVx59C00pn2lfDp/V84vLL9Rft9s5ldyYt2q5+esndjWuwp61ww1WJ5drym7VB5Pi9Md2OO8vXdAdfT4Nj8mNCpu830Lpf2b+ZpQsPQVkYlFvE6GK1asQO3adZDdw1OzTCpOPwGE12+EG1f/haeXF2YuWY1jh/ajZb1v0b11Y1y/fAn5crghj7cb+g4ZiedPH+P76t+gZukCAID8BQvj18mzsGnNcvwYUR3Xr1xCx579dI49fuZ8vEtMQOv6NdG+fXsMGDDAICEpALvnbcnl6aqptclMtr5LX9j2G97rjvtBN+N3MTP5c/R1qZr1kuu5SsWY3LQERjUoigBPfk3Lm3pWMlg2+Dvb1ULs7lfN4m07VgnWXcDwz4jcqHQghkUUsfjYzkL73KBf41ounzeG1zN8jS3LG08sbEm/pbVdKppfSQuf80wBP3f82qCo4efrADmycTftfql9KClY+or4ebhAJjEfZOzevRsH9uuOHsz4QZcsWw5XnrxFoaIlEF7/B2w+cAIX78Xh2JUYzF66FjKJGD7ZZCj1TQVs+ecULsTEQqlSw+3TCaxl+y44eO46zt55it/+WIxu/Qdjf9RVzXGKliiFDXuP4HzMC/z3339o0aIFHj58iJ+69dasw7IserRvZYu35ItUJshL8++GpXKh2Te5eW3XuWqITk6caQKnHQjy4VcD+L++VQXtl499A6qjekHhWaK9s8nQLiwfun+bX7Psz/bl0LNGftyf0sDoNnm83dC6wueLq082Gdpp1egwVk6yUzKPp9l1fq5jvOO22Mg8eTnd+dWS9qyR3/xKDiThOQeg9uttF5aPY83PZCaaueqXED5naKX8OQStXyI39+ftbMFHYTP9ik4Oq22yzOYCLS6behjepGQmCpa+IjKxY4ZZiEUM8nibvpDKeQRw+hiGQYCH+ZoAW7/irDBSZclP5QRvM7J++t22qTtsa3SrFqLT/6O0VjBnK8UCPTCxcQnN35143IEbCywAIKJ4AEbWL8p7gt4R9YvA202KiOL+CC/qj5zu/C8Ihfwta65rG5bX6HK+AYWjFTDSTMnVfNa7ZigODKyObtVCBNX2eLhaF2j8HF4QVUKFBT+W2N2vGoJzuBn8dssEeWGnDW4uzDUd/9akBOfz2obX56599HSzT418mMAg1NYoWPpKBHq5wt2KUVPaF5ZQX+EneIlYZPION5vcsiY1Pw8X5DB718wgX45scJfb5u5M/2K0qnMFm+z3wMDqJp/j038lvGh6PqtATxfezUnaTXQ1ClvXIZnL6O+L4btiwvJtWWtUw6LmV7IhhmHwZ/vyWN6xvFV9Vvj2VbJVc23L8nkEb2PpRKfaXQDaGQn29v9cHf1rFzC67fB6RVDALztGf18MW3tXxuDvCll147KmS0VNbTcXN5kEf7QqY/mBeCqZxxPHhtZCPb2arNENiyK/BedboX6qxK8GDgA8Mnn0beX8OdCmon3mXxWCgqWvBN+qeGNye7nCXS5Bjmwy5PZyRTaOwENswRksRzYZgnzc7DYE3tNVardOibUKG/anskSRAMP+Qed+rYNZP5bGABNNLtqGRBTGrB9Lm70L1f54GpbKZXa/kYNrYF6bsmbXA6DTObrVpxqq5t+kX4yLBXpgafty2NPf8v44tuAsQ5NzfQpo65XQ/QwiB6fnLmtYKjBTyjHegg7D9Uua/94YUzSXB5Z1KI89/auhfaV8mN2yNCoEp0/10aZiXjAMg8F1C2O0mUDXL7sL+tcpCD+BgzC0++DVKOSL1hWM187p8/dwwZouFZ3igu3shkYUtvk+/+5RCVObOX7KHAqWiElFc3mggJ87crjLwTAMcnu7ma3J0W/7zyYzX6PDMAy83WQm+w1YI++nDp72GKFib/4eLmhRLg+v98VFKkaLcnngZ6RpUrsPTf9axu/cTdVUhPq6o1FpfhfuErk98b++VXH+1zqY1KQENnQPw5Rmn6v36xYPMNs/Q19dATVSgV7pr10iYkw2R9kiNQAfLStwX1gP/PwttvSqbPDeZkwN0vyb3Fb179DG9dV3k0kQ5OMKF6nIbI3xsSE1ceiXb+HhIsUkrWYbIc2O3xXzR4ncnpCIRWj2TR6s6xaGDd3DdEZ5da4ago08+qdIeYzs1WZNoFyjkC+vOdwalBTWx4nPjZAzMXcu8vjUt1Vi4rOROKgriC1QsJSF2TvDrFQsghuPYIeLj9YJ39wPReidojluMonJkSbFcnkIvnCbcmxITSxtL7yfEF/OOiu5sX4QpYO8Pg0kEKFKaE6L+qM1KBmA0nk8ET06HH8KeF/lEjFuTIjA9QkRYBgGoxoY1lAIrb3UH1KewVzsXcg/Oy6P/c7k855uUlQI9jG5H4ZheKUx4MPc3GxHB9fElXF14SIVc3YmDs6ZDQX90wOO9pXy4cyI2rg5McJk0NKyfB7sHcBdkyiXiFElNKfORVgsYlApfw6Y6361uF05s31xAODXBkWQ18cNQ+vxr/UI9BSeruTSmO8EjT6ViBib1Uzrm9TYPikG+ASxANDHSHoGANjaq4oti5OpKFjKwrxsnJ3Xy02GfDwDsPy+7pyJ0vJ4u8HbTQYvrc5+ObPJ4eUmMxnkScUiziY+objOtWIRA5GNapuCc2ZD3eLCR83w1bhM5jTJCJVbq9P+vgGm+1wJtahdOfyvXzVNjaYQ2eQSzfyHZYxMJSGUNc3Xxn6f35fKhRUdbZM0kS9zo/MkYpEmqK0cmgPtwvJiIo+LbaCXK+fN1IwWpVE80PIbEnPdskrm8cTpEbXN7qfHt6E4MawWcgkIgCY2ER5s+GSTCfq++tio5tCY9pWD0eNb249u/IZH7RoA5DBR2xjk44b/fquPZmVzY04m9AWzJecak0gMFPRzR4pChWcJH+x6HBHDCKqpcpdLkNfHDXdfJht93iebzOBkIBJ9PsbjN8Km9DDF0sE/fE5q1g4Bt0SnKsE4cy9eZxi8qSptR9PujJwvC2YQ59PB19bmtymr892zpAYDAFizoUS6bAJfI8MwmNw0vQP32P/dEFwuZyMRCf/tNC2bG37ZDZuzixrpV+jMtG9mbdHFwdToUWNye5k+H8gkIszOYoESQDVLTs9VJkEOdzlCcmaDXCLWjOrKyDDtiAu6M/F1l1uc7dgcU00w9lS3eABODquFVZ34jbIrl4/fnZ49lMvnjbmty2Bem7I2rRHUt+Sncjr5n6y1unMFFPBzx19dw8yvbGe2Tq6qP+rTVoF2Vsva3KdmKL7J68VrEIM+U2fUknk8sbJTefzzy7cG6S/MfT/rFvPH3NZlBJfFGt2qfa5Z4qqd5jtSVfu7ZW6gRsUQH1QtYP1Qf2fK/UU1S1lEdhcpCgcY9rfwcpPibYpC0L6yySV4n6rUWSbkrsGZSMQiFPTPjqQPaUhVqvEi8XMNHN88OUD6KD6VXi9nc5VP+v07RAyg5jmku2KID84/eGP0uSCeNXz9axdAZ4FZsyNKBGDekRheOapM2dWvKo7cfoke3+bXNHnZU8Zw6mFbr5pZk5+ahf1Q08K+IrWL2KePCR/eblK8TeGeUNrbDk07hf2zY6WNUmTYw9CIwph58I7OjcMwI1m6baF2kfTAYkbzUoiYc0Kz3Fx+sqUdyiNVqeJcx9Y83aR4OK0hAGD5ScMJgXt8mx+/GunXxwef/p49vw3F6Zh4i/afIZ+P8wTpVLP0FcqfMxv8srsgX45sCMmZDa5SscMmYh3zSx/82LyZ5u/2TRtgxviRJtc3VZ3s4So1mM8ttxf/gOD8mZMoHeSNpMREs+vOalEaxQM9sK6bbs3Ell5VUDyQX1X9+m5hVicQHFy3sOB+D8UDPXFyWC0cHVLT4uOWyuOFgeGFMiVQcib1igfYtSO/s/q9ZWleHakdpU/NUJwcVgtbBY50LMUjU7ophQOyY27rMsjvmw2be2bOCEtrtA3LiwrB3hhRvwgmNi6Osnm9THbCNsVek/muETg9jKNQsPQVYhgGAZ4u8HSVIruLFAX9s8NVr6Nmp06dwDAMGIaBTCZDgQIFMHHiRCiVShN7taY8n/+9a+cOTJo4EYX8jQ/zzev9Oag7duwYGIZBQkKC1r7Sd+Yul/Ca2iWjz4ixIffZXaSQiUUGo9HK5vPG3gHVUSqPl87ycp+Wm8sTA6R3Zs+spg39+QCDfNzsPreeMyiZ29OmTak1CvtqmrW0PzuufkeVeWQdXt6hPNxkYixupzuSyty0Evr++eVbo8stfQ/WdwvD9OYlLRo1aosksGU/NXWZuyFgGAZBPm6CBwM0Kh2IGc1LmXzfzGlcJjeODK6JiiH8Ri3KxCJUtMEIxxUdywvub+cmk2BLryroVSMUHSoHY0efqoIHCPWqYT64sqRLRI1Cuglx8+VwntokbRQsfcEs7TyaoV69enjx4gXu3r2LwYMHY/z48Zg5c6bBemkKBQI8XHiPpAPS+xoB6U1l2qPScubMgZBAX4Nai7w+bgjwcIGbmZNwQT935HSXG23KyhgNo52iIGd2OUrk9jTa50YsYlA4IDvyav14+dQGdaueH3d+q4fyNuxPtLJTeVTK76OZlkSIrtVC0LNGfqe6Aw78lJTR2mDG38P0aDUXqRjRo00P3+djYPjnPDg/lvuc7bpjlWAUzeWB2kX8OPtmtDExLYm28GL+uD4+wiDZY++aoWjCYyRks7K5ETm4hskbjEAvV4NJkvmoWiAnWvFM3Jhhe58qqBjiw3uIOZdF7cqhS9UQbOttn+HmIhGDlhWCTL5vtsYwjNFJmLkUMhIw1yma/n2xNXOzEXiZmcbEXS7hnZONi3YqCmdKj0fB0hfMx10GH46h+ubI5XIEBAQgX7586N27N8LDw7Fr1y506tQJTZo0wfRpUxFeriga1awAPw8XJMXHoWXLlvDy8oKPjw8aN26Mhw8favanUqkwaNAgeHl5oURoHqyZM9mg30/NmjUxcOBAzd+pqakYPnw4ShYORZCvJwoUKIAVK1bg4cOHqFWrFgDA29sbDMOgU6dOcJGKEeAhx6wZ0xESEgJXV1eULl0aW7duhW92OYoEeMDfwwX79u1DoUKF4Orqijq1a+uUU1vG3Wqorzuyu0h5341Zkl+IS+0i/tjYozLyeAv/LF2kYoysX5T3HbAxGZmWbTWv21/dwtCodKDFF8KI4v44P6oOTgyrxbmedrMtV2BlSuMyuRE1sjYeTG2g01laLhFj/8/VsbJTBUE1GqaSfxrrX+ciFeOX7z7PqWcqJ8+4RsXNJpTsXDUE67uFoWnZ3BYF3FwyptrJ6S7DN3m9sblnZZvkMAvwdMHYH4pluc7lwP/bu/eopq58D+DfAEkAAwQEAiggCIIoouKUxiraQgHttb4qailFa3F84EirttqOinVa1Nbe0a4WvTqKM9f66Pgcn2NRULlA1RERYbAwVHQGRKWAgMgjv/sH5dQIhKDhEfh91spa5Jydc/bvnAP5sc8+ewMH5jf/j4k218qTrUYtTS3Slv6Y2nr6+pozSnN/yKdbybZHjFD7ffPSskuCvuBkqaMRATWVOnuJVVUQ1Ta8LMV1ws+i2ioY1Fahr4wgN6ptKP+cE0qZmJigpqahM3lCQgJ+vJmDLd8exFc796K2thbBwcEwMzPDhQsXkJycDJlMhpCQEOEzGzduRHx8PHbs2IGLFy+irPRnHDp0SOM+3377bezZswebN29GdnY2tm7dCplMBkdHRxw4cAAAkJOTg8LCQmzatAkAEBsbiz//+c/YsmULbty4gffeew9vvfUWkpKSIDEywJ07dzBlyhRMmDAB6enpePfdd7F8+XKN9eglNYKD3KRNHeEbO19bmoqbHdm3cRyUtoxS3diJVdcd8ltrMdvyli9WjPPE9rd1M0ZQfxsZNs8c1qb/6mf8Mir2x+MHYmv4CNiaGes8KW2OvYWJTkaAXxbs8Vxfcm29Lfe0l9ys8d/Th7baQtBWXg7mSFo2ttXEtSfxdbZCfAstNY2thVEtzIO38r+84Glnhg1TO3eKj7n+rjjznj/Evwwm/PQ/W//7rh++f39Mi5+3lknxf8tfESa1freV5Kur46fhOlptFfCZ7gYZtPvl1UjjMxkf/QeQtP2/NCJCQkICTp8+jUWLFuHevXvo1asXtv7PdvyrpBoAsG/fPqhUKmzfvl34Ytm5cyfkcjkSExMRFBSEP/7xj1ixYgWmTGno0L1lyxacPn26xf3evHkT+/fvx5kzZxAYGAgAcHX99VFSK6uGX15bW1vI5XIADS1Rn332Gb7//nsolUrhMxcvXsTWrVsxZswYxMXFoX///ti4cSMAwMPDA9evX8f69evbfGw0eW2IPQY5jEVfSxMYGRpgxB/O4H7Fr08uThvhiBH9rNrU8mdnYYyUFa/obB69yNEueFBR0+ws8E/qLZPit1r0WXgWb/o54du0glbLfTbZG3P9XfWqpWHYEy1xC1uYakbXYiZ4IeZvWR2yr0ZdtZ9JZxozwAb/O8evye/WxtCh+F2Ae4vXcV9LU5yKbr0f1bFFo/BfX10E0DCUzL2Hj5+7zjtn/Qaz4y8BaBhCwV1hhvRVQSh7VNtkJHiJkYFabM1Nz9N4Czhc6QzXZ/i91dUo9rrAyRJr0bFjxyCTyVBbWwuVSoU333wTMTExWLhwIby9vSEzNUYfEsFQJMJfrl1Dbm4uzMzU//utrq5GXl4eysrKUFhYCD+/X58gMzIywogRI0AttHilp6fD0NAQY8a0/N/L03Jzc1FVVYVXX1Xvq1JTU4NhwxomhM3OzlarBwAhsdK1fq38gXiWL/62jETcmo9fa3tfFl37dNJg5BVXIK2FoRQaGRiIOmQGdl1ytDLF9++PgeUztuY8edtX29ZEr+cYNZvpjkgkwqgnBpdtZKij6/jpW50vufVGcu6DZxpbqtHQZm6z95IaaRxHbWu4L4rLq4WpcJ4mEolavU38tKsrX8X9iset/hPXkThZ6mhi04YWHh15XFuPm7+Moj3IwVzzFB7itvV3efnllxEXFweJRAIHBwcYGf16ufTq1fAl37tXQz+QiooK+Pr6Yvfu3U22Y2Nj02SZNkxM2p4UVFQ0HIvjx4+jT58+auukUt3OPddWiwMHYOXhTLzxREfhrqyjWnBEIhEGOVi0mizpq+f5g29hIsa+uS9CbGSA20+Mev/kE2JPj9Lt0cqtzZH9G77AO2PQVX2gr5O9fhPmi3P/LNZ6kMnmyJ64JrTtnxmsw6meGvs8WfaStMuYYc+Df1s6mkj0TLfCWt5ePUisavhZ0kunjw/06tULbm7a3ToYPnw49u3bB1tbW5ibN9+xz97eHmlpafD3b2hirqurw5UrVzB8ePOTT3p7e0OlUiEpKUm4DfckiaThl6m+/tfB3ry8vCCVSlFQUNBii9TAgQNx9OhRtWWpqamtB/mcwl90hr+7NRyfoZN2R8qICUJNnUpnt/q08d6r7ih7VIvXu+g8eJ3J75fhB3z6yvFDfglG9LOE1MgQV1e+CpGo6SjdFqZiXPo4EMbi5rukOlqZInVFQIuTTPdUH433xJ4fbmNJkPYT7nYlFiZiTBrWp/WCGogNDZC+6lUQ6WaKFG19Mc0HmxJu4otpPh22z7biZEnP6aLjqS6EhYXh888/x8SJE/HJJ5+gb9++uHXrFg4ePIgPPvgAffv2xeLFi7Fu3Tq4u7vD09MTX375pdoYSU/r168fIiIi8M4772Dz5s3w8fHBrVu3UFxcjNDQUDg7O0MkEuHYsWMYP348TExMYGZmhqVLl+K9996DSqXCqFGjUFZWhuTkZJibmyMiIgLz5s3Dxo0bsWzZMrz77ru4cuUK4uPjO+Q46UPfjpaewGlPZsZibAxt3z+UHdEZvD0ZGvw6bxugebTupwdofZqdxbOP4N5dzfXvj7n+7dMvr73pcsBIXU/Qro03fPt2+RZ3fhpOz0mMDNBbJoWtmVTzLbh2ZmpqivPnz8PJyQlTpkzBwIEDMWfOHFRXVwstTUuWLEF4eDgiIiKgVCphZmaGyZMna9xuXFwc3njjDSxYsACenp6IjIxEZWUlAKBPnz5Ys2YNli9fDoVCgaioKADA2rVrsXLlSsTGxmLgwIEICQnB8ePH4eLS8DSGk5MTDhw4gMOHD8PHxwdbtmzBZ599BqDhj86zPJ7Puq6v3xwO596m+Cas+RZMxvTVN2EN1/aWt3reyPIdTUQt9a5lWisvL4eFhQXKysqa3IKqrq5Gfn4+XFxcYGzM/83pMz6XjDHWvWj6/n4StywxxhhjjGnAyRJjjDHGmAacLDHGGGOMacDJEmOMMcaYBpwsMcYYY4xpwMlSB+GHDvUfn0PGGOuZOFlqZ4aGDQPh1dTUtFKSdXVVVQ3TTYjFPPIxY4z1JDyCdzszMjKCqakp7t27B7FYDAMDzk/1DRGhqqoKxcXFkMvlQgLMGGOsZ+BkqZ2JRCLY29sjPz8ft27d6uzqsOcgl8thZ6e7SSMZY4zpB71Jlj799FMcP34c6enpkEgkGucUa0REWL16NbZt24bS0lK89NJLiIuLg7u7u1CmpKQEixYtwt/+9jcYGBhg6tSp2LRpE2SyZ58p/GkSiQTu7u58K06PicViblFijLEeSm+SpZqaGkybNg1KpRJ/+tOftPrMhg0bsHnzZuzatQsuLi5YuXIlgoODkZWVJUxXERYWhsLCQpw5cwa1tbWYPXs25s6di2+//Van9TcwMOApMhhjjDE9pHdzw8XHxyM6OrrVliUigoODA5YsWYKlS5cCAMrKyqBQKBAfH48ZM2YgOzsbXl5euHTpEkaMGAEAOHXqFMaPH487d+7AwcFBqzppO7cMY4wxxrqOHj83XH5+PoqKihAYGCgss7CwgJ+fH1JSUgAAKSkpkMvlQqIEAIGBgTAwMEBaWlqL2378+DHKy8vVXowxxhjrnrptslRUVAQAUCgUassVCoWwrqioCLa2tmrrjYyMYGVlJZRpTmxsLCwsLISXo6OjjmvPGGOMsa6iU/ssLV++HOvXr9dYJjs7G56enh1UI+2sWLEC77//vvC+rKwMTk5O3MLEGGOM6ZHG7+3WeiR1arK0ZMkSzJo1S2MZV1fXZ9p24yPed+/ehb29vbD87t27GDp0qFCmuLhY7XN1dXUoKSnR+Ii4VCqFVCoV3jcebG5hYowxxvTPw4cPYWFh0eL6Tk2WbGxsYGNj0y7bdnFxgZ2dHRISEoTkqLy8HGlpaZg/fz4AQKlUorS0FFeuXIGvry8A4OzZs1CpVPDz89N6Xw4ODrh9+zbMzMwgEol0FkN5eTkcHR1x+/btHtNxnGPmmLuznhg3x8wxd2VEhIcPH7b6QJfeDB1QUFCAkpISFBQUoL6+Hunp6QAANzc3YUwkT09PxMbGYvLkyRCJRIiOjsYf/vAHuLu7C0MHODg4YNKkSQCAgQMHIiQkBJGRkdiyZQtqa2sRFRWFGTNmaP0kHNAwLEDfvn11HbLA3Nxcry4+XeCYe4aeGDPQM+PmmHsGfYxZU4tSI71JllatWoVdu3YJ74cNGwYAOHfuHMaOHQsAyMnJQVlZmVDmgw8+QGVlJebOnYvS0lKMGjUKp06dUhvvaPfu3YiKikJAQIAwKOXmzZs7JijGGGOMdXl6N85ST9ITx2/imDnm7qwnxs0xc8zdQbcdOqA7kEqlWL16tVpn8u6OY+4ZemLMQM+Mm2PuGbp7zNyyxBhjjDGmAbcsMcYYY4xpwMkSY4wxxpgGnCwxxhhjjGnAyRJjjDHGmAacLHVhX3/9Nfr16wdjY2P4+fnhhx9+6OwqNRETEwORSKT2enIuv+rqaixcuBC9e/eGTCbD1KlTcffuXbVtFBQU4LXXXoOpqSlsbW2xbNky1NXVqZVJTEzE8OHDIZVK4ebmhvj4+CZ1ac/jdf78eUyYMAEODg4QiUQ4fPiw2noiwqpVq2Bvbw8TExMEBgbixx9/VCtTUlKCsLAwmJubQy6XY86cOaioqFArk5GRgdGjR8PY2BiOjo7YsGFDk7p899138PT0hLGxMby9vXHixIk210UXMc+aNavJuQ8JCdHbmGNjY/Gb3/wGZmZmsLW1xaRJk5CTk6NWpitdz9rURRcxjx07tsl5njdvnt7GHBcXhyFDhgiDJyqVSpw8ebJN+9CneLWNu7udZ50j1iXt3buXJBIJ7dixg27cuEGRkZEkl8vp7t27nV01NatXr6ZBgwZRYWGh8Lp3756wft68eeTo6EgJCQl0+fJlevHFF2nkyJHC+rq6Oho8eDAFBgbS1atX6cSJE2RtbU0rVqwQyvzrX/8iU1NTev/99ykrK4u++uorMjQ0pFOnTgll2vt4nThxgj7++GM6ePAgAaBDhw6prV+3bh1ZWFjQ4cOH6dq1a/T666+Ti4sLPXr0SCgTEhJCPj4+lJqaShcuXCA3NzeaOXOmsL6srIwUCgWFhYVRZmYm7dmzh0xMTGjr1q1CmeTkZDI0NKQNGzZQVlYW/f73vyexWEzXr19vU110EXNERASFhISonfuSkhK1MvoUc3BwMO3cuZMyMzMpPT2dxo8fT05OTlRRUSGU6UrXc2t10VXMY8aMocjISLXzXFZWprcxHz16lI4fP043b96knJwc+uijj0gsFlNmZqZW+9C3eLWNu7udZ13jZKmLeuGFF2jhwoXC+/r6enJwcKDY2NhOrFVTq1evJh8fn2bXlZaWklgspu+++05Ylp2dTQAoJSWFiBq+kA0MDKioqEgoExcXR+bm5vT48WMiIvrggw9o0KBBatuePn06BQcHC+878ng9nTioVCqys7Ojzz//XFhWWlpKUqmU9uzZQ0REWVlZBIAuXboklDl58iSJRCL697//TURE33zzDVlaWgpxExF9+OGH5OHhIbwPDQ2l1157Ta0+fn5+9Nvf/lbruugiZqKGZGnixIktfkbfYy4uLiYAlJSUJGyzq1zP2tRFFzETNXyJLl68uMXP6HvMRESWlpa0ffv2HnGOm4ubqGec5+fBt+G6oJqaGly5cgWBgYHCMgMDAwQGBiIlJaUTa9a8H3/8EQ4ODnB1dUVYWBgKCgoAAFeuXEFtba1aHJ6ennBychLiSElJgbe3NxQKhVAmODgY5eXluHHjhlDmyW00lmncRmcfr/z8fBQVFant38LCAn5+fmpxyuVyjBgxQigTGBgIAwMDpKWlCWX8/f0hkUiEMsHBwcjJycHPP/8slNF0LLSpiy4lJibC1tYWHh4emD9/Ph48eCCs0/eYG6dOsrKyAtC1rmdt6qKLmBvt3r0b1tbWGDx4MFasWIGqqiphnT7HXF9fj71796KyshJKpbJHnOPm4m7UXc+zLujN3HA9yf3791FfX692UQKAQqHAP//5z06qVfP8/PwQHx8PDw8PFBYWYs2aNRg9ejQyMzNRVFQEiUQCuVyu9hmFQoGioiIAQFFRUbNxNq7TVKa8vByPHj3Czz//3KnHq7Geze3/yRhsbW3V1hsZGcHKykqtjIuLS5NtNK6ztLRs8Vg8uY3W6qIrISEhmDJlClxcXJCXl4ePPvoI48aNQ0pKCgwNDfU6ZpVKhejoaLz00ksYPHiwsJ+ucj1rUxddxAwAb775JpydneHg4ICMjAx8+OGHyMnJwcGDB/U25uvXr0OpVKK6uhoymQyHDh2Cl5cX0tPTu/U5biluoHueZ13iZIk9l3Hjxgk/DxkyBH5+fnB2dsb+/fthYmLSiTVj7W3GjBnCz97e3hgyZAj69++PxMREBAQEdGLNnt/ChQuRmZmJixcvdnZVOkxLMc+dO1f42dvbG/b29ggICEBeXh769+/f0dXUCQ8PD6Snp6OsrAx//etfERERgaSkpM6uVrtrKW4vL69ueZ51iW/DdUHW1tYwNDRs0vv/7t27sLOz66RaaUcul2PAgAHIzc2FnZ0dampqUFpaqlbmyTjs7OyajbNxnaYy5ubmMDEx6fTj1bgPTfu3s7NDcXGx2vq6ujqUlJTo5Fg8ub61urQXV1dXWFtbIzc3V6iLPsYcFRWFY8eO4dy5c+jbt6+wvCtdz9rURRcxN8fPzw8A1M6zvsUskUjg5uYGX19fxMbGwsfHB5s2berW51hT3M3pDudZlzhZ6oIkEgl8fX2RkJAgLFOpVEhISFC7v9wVVVRUIC8vD/b29vD19YVYLFaLIycnBwUFBUIcSqUS169fV/tSPXPmDMzNzYXmYaVSqbaNxjKN2+js4+Xi4gI7Ozu1/ZeXlyMtLU0tztLSUly5ckUoc/bsWahUKuGPklKpxPnz51FbWyuUOXPmDDw8PGBpaSmU0XQstKlLe7lz5w4ePHgAe3t7oa76FDMRISoqCocOHcLZs2eb3B7sStezNnXRRczNSU9PBwC186xPMTdHpVLh8ePH3fIcaxN3c7rjeX4unda1nGm0d+9ekkqlFB8fT1lZWTR37lySy+VqTyJ0BUuWLKHExETKz8+n5ORkCgwMJGtrayouLiaihkdAnZyc6OzZs3T58mVSKpWkVCqFzzc+jhoUFETp6el06tQpsrGxafZx1GXLllF2djZ9/fXXzT6O2p7H6+HDh3T16lW6evUqAaAvv/ySrl69Srdu3SKihkfX5XI5HTlyhDIyMmjixInNDh0wbNgwSktLo4sXL5K7u7vaY/SlpaWkUCgoPDycMjMzae/evWRqatrkMXojIyP64osvKDs7m1avXt3sY/St1eV5Y3748CEtXbqUUlJSKD8/n77//nsaPnw4ubu7U3V1tV7GPH/+fLKwsKDExES1x6erqqqEMl3pem6tLrqIOTc3lz755BO6fPky5efn05EjR8jV1ZX8/f31Nubly5dTUlIS5efnU0ZGBi1fvpxEIhH9/e9/12of+havNnF3x/Osa5wsdWFfffUVOTk5kUQioRdeeIFSU1M7u0pNTJ8+nezt7UkikVCfPn1o+vTplJubK6x/9OgRLViwgCwtLcnU1JQmT55MhYWFatv46aefaNy4cWRiYkLW1ta0ZMkSqq2tVStz7tw5Gjp0KEkkEnJ1daWdO3c2qUt7Hq9z584RgCaviIgIImp4fH3lypWkUChIKpVSQEAA5eTkqG3jwYMHNHPmTJLJZGRubk6zZ8+mhw8fqpW5du0ajRo1iqRSKfXp04fWrVvXpC779++nAQMGkEQioUGDBtHx48fV1mtTl+eNuaqqioKCgsjGxobEYjE5OztTZGRkk+RUn2JuLlYAatdaV7qetanL88ZcUFBA/v7+ZGVlRVKplNzc3GjZsmVq4+/oW8zvvPMOOTs7k0QiIRsbGwoICBASJW33oU/xahN3dzzPuiYiIuq4dizGGGOMMf3CfZYYY4wxxjTgZIkxxhhjTANOlhhjjDHGNOBkiTHGGGNMA06WGGOMMcY04GSJMcYYY0wDTpYYY4wxxjTgZIkxprdmzZqFSZMmdXY1GGPdHCdLjLEuSSQSaXzFxMRg06ZNiI+P75T6bdu2DT4+PpDJZJDL5Rg2bBhiY2OF9ZzIMdZ9GHV2BRhjrDmFhYXCz/v27cOqVauQk5MjLJPJZJDJZJ1RNezYsQPR0dHYvHkzxowZg8ePHyMjIwOZmZmdUh/GWPviliXGWJdkZ2cnvCwsLCASidSWyWSyJq03Y8eOxaJFixAdHQ1LS0soFAps27YNlZWVmD17NszMzODm5oaTJ0+q7SszMxPjxo2DTCaDQqFAeHg47t+/32Ldjh49itDQUMyZMwdubm4YNGgQZs6ciU8//RQAEBMTg127duHIkSNCS1hiYiIA4Pbt2wgNDYVcLoeVlRUmTpyIn376Sdh2Y0xr1qyBjY0NzM3NMW/ePNTU1Ojs2DLG2oaTJcZYt7Jr1y5YW1vjhx9+wKJFizB//nxMmzYNI0eOxD/+8Q8EBQUhPDwcVVVVAIDS0lK88sorGDZsGC5fvoxTp07h7t27CA0NbXEfdnZ2SE1Nxa1bt5pdv3TpUoSGhiIkJASFhYUoLCzEyJEjUVtbi+DgYJiZmeHChQtITk6GTCZDSEiIWjKUkJCA7OxsJCYmYs+ePTh48CDWrFmj2wPFGNNep07jyxhjWti5cydZWFg0WR4REUETJ04U3o8ZM4ZGjRolvK+rq6NevXpReHi4sKywsJAAUEpKChERrV27loKCgtS2e/v2bQJAOTk5zdbnP//5D7344osEgAYMGEARERG0b98+qq+vb7FuRER/+ctfyMPDg1QqlbDs8ePHZGJiQqdPnxY+Z2VlRZWVlUKZuLg4kslkattnjHUcbllijHUrQ4YMEX42NDRE79694e3tLSxTKBQAgOLiYgDAtWvXcO7cOaEPlEwmg6enJwAgLy+v2X3Y29sjJSUF169fx+LFi1FXV4eIiAiEhIRApVK1WLdr164hNzcXZmZmwr6srKxQXV2tti8fHx+YmpoK75VKJSoqKnD79u1nOCKMsefFHbwZY92KWCxWey8SidSWiUQiABCSmoqKCkyYMAHr169vsi17e3uN+xo8eDAGDx6MBQsWYN68eRg9ejSSkpLw8ssvN1u+oqICvr6+2L17d5N1NjY2mgNjjHUaTpYYYz3a8OHDceDAAfTr1w9GRs/+J9HLywsAUFlZCQCQSCSor69vsq99+/bB1tYW5ubmLW7r2rVrePToEUxMTAAAqampkMlkcHR0fOb6McaeHd+GY4z1aAsXLkRJSQlmzpyJS5cuIS8vD6dPn8bs2bObJDuN5s+fj7Vr1yI5ORm3bt1Camoq3n77bdjY2ECpVAIA+vXrh4yMDOTk5OD+/fuora1FWFgYrK2tMXHiRFy4cAH5+flITEzE7373O9y5c0fYfk1NDebMmYOsrCycOHECq1evRlRUFAwM+E82Y52Bf/MYYz2ag4MDkpOTUV9fj6CgIHh7eyM6OhpyubzF5CQwMBCpqamYNm0aBgwYgKlTp8LY2BgJCQno3bs3ACAyMhIeHh4YMWIEbGxskJycDFNTU5w/fx5OTk6YMmUKBg4ciDlz5qC6ulqtpSkgIADu7u7w9/fH9OnT8frrryMmJqYjDgdjrBkiIqLOrgRjjLEGs2bNQmlpKQ4fPtzZVWGM/YJblhhjjDHGNOBkiTHGGGNMA74NxxhjjDGmAbcsMcYYY4xpwMkSY4wxxpgGnCwxxhhjjGnAyRJjjDHGmAacLDHGGGOMacDJEmOMMcaYBpwsMcYYY4xpwMkSY4wxxpgGnCwxxhhjjGnw/4z81ecvoyK9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_test_inv, label=\"Actual\")\n",
    "plt.plot(y_pred_inv, label=\"Predicted\")\n",
    "plt.title(\"LSTM Forecasting: Sentiment Score\")\n",
    "plt.xlabel(\"Time Step\")\n",
    "plt.ylabel(\"Sentiment Score\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9oXdiJZ0vdRY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hXM8WFwsvdOi"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
